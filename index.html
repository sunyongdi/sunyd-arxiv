<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                xiximayou-arxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2023-11-21T00:00:00Z">2023-11-21</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LowResource at BLP-2023 Task 2: Leveraging Bangla<span class="highlight-title">Bert</span> for Low Resource
  Sentiment Analysis of Bangla Language <span class="chip">EMNLP2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12735v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12735v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aunabil Chakma, Masum Hasan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes the system of the LowResource Team for Task 2 of
BLP-2023, which involves conducting sentiment analysis on a dataset composed of
public posts and comments from diverse social media platforms. Our primary aim
is to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus,
using various strategies including fine-tuning, dropping random tokens, and
using several external datasets. Our final model is an ensemble of the three
best BanglaBert variations. Our system has achieved overall 3rd in the Test Set
among 30 participating teams with a score of 0.718. Additionally, we discuss
the promising systems that didn't perform well namely task-adaptive pertaining
and paraphrasing using BanglaT5. Training codes and external datasets which are
used for our system are publicly available at
https://github.com/Aunabil4602/bnlp-workshop-task2-2023
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at BLP Workshop @EMNLP2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Soft Random Sampling: A Theoretical and Empirical Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodong Cui, Ashish Mittal, Songtao Lu, Wei Zhang, George Saon, Brian Kingsbury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soft random sampling (SRS) is a simple yet effective approach for efficient
training of large-scale deep neural networks when dealing with massive data.
SRS selects a subset uniformly at random with replacement from the full data
set in each epoch. In this paper, we conduct a theoretical and empirical
analysis of SRS. First, we analyze its sampling dynamics including data
coverage and occupancy. Next, we investigate its convergence with non-convex
objective functions and give the convergence rate. Finally, we provide its
generalization performance. We empirically evaluate SRS for image recognition
on CIFAR10 and automatic speech recognition on Librispeech and an in-house
payload dataset to demonstrate its effectiveness. Compared to existing
coreset-based data selection methods, SRS offers a better accuracy-efficiency
trade-off. Especially on real-world industrial scale data sets, it is shown to
be a powerful training strategy with significant speedup and competitive
performance with almost no additional computing cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Keeping Users Engaged During Repeated Administration of the Same
  Questionnaire: Using Large Language Models to Reliably Diversify Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hye Sun Yun, Mehdi Arjmand, Phillip Raymond Sherlock, Michael Paasche-Orlow, James W. Griffith, Timothy Bickmore
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Standardized, validated questionnaires are vital tools in HCI research and
healthcare, offering dependable self-report data. However, their repeated use
in longitudinal or pre-post studies can induce respondent fatigue, impacting
data quality via response biases and decreased response rates. We propose
utilizing large language models (LLMs) to generate diverse questionnaire
versions while retaining good psychometric properties. In a longitudinal study,
participants engaged with our agent system and responded daily for two weeks to
either a standardized depression questionnaire or one of two LLM-generated
questionnaire variants, alongside a validated depression questionnaire.
Psychometric testing revealed consistent covariation between the external
criterion and the focal measure administered across the three conditions,
demonstrating the reliability and validity of the LLM-generated variants.
Participants found the repeated administration of the standardized
questionnaire significantly more repetitive compared to the variants. Our
findings highlight the potential of LLM-generated variants to invigorate
questionnaires, fostering engagement and interest without compromising
validity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Understand Content and Propagation for
  Misinformation Detection: An Empirical Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengyang Chen, Lingwei Wei, Han Cao, Wei Zhou, Songlin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have garnered significant attention for their
powerful ability in natural language understanding and reasoning. In this
paper, we present a comprehensive empirical study to explore the performance of
LLMs on misinformation detection tasks. This study stands as the pioneering
investigation into the understanding capabilities of multiple LLMs regarding
both content and propagation across social media platforms. Our empirical
studies on five misinformation detection datasets show that LLMs with diverse
prompts achieve comparable performance in text-based misinformation detection
but exhibit notably constrained capabilities in comprehending propagation
structure compared to existing models in propagation-based misinformation
detection. Besides, we further design four instruction-tuned strategies to
enhance LLMs for both content and propagation-based misinformation detection.
These strategies boost LLMs to actively learn effective features from multiple
instances or hard instances, and eliminate irrelevant propagation structures,
thereby achieving better detection performance. Extensive experiments further
demonstrate LLMs would play a better capacity in content and propagation
structure under these proposed strategies and achieve promising detection
performance. These findings highlight the potential ability of LLMs to detect
misinformation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fair Text Classification with Wasserstein Independence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12689v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12689v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thibaud Leteno, Antoine Gourru, Charlotte Laclau, Rémi Emonet, Christophe Gravier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group fairness is a central research topic in text classification, where
reaching fair treatment between sensitive groups (e.g. women vs. men) remains
an open challenge. This paper presents a novel method for mitigating biases in
neural text classification, agnostic to the model architecture. Considering the
difficulty to distinguish fair from unfair information in a text encoder, we
take inspiration from adversarial training to induce Wasserstein independence
between representations learned to predict our target label and the ones
learned to predict some sensitive attribute. Our approach provides two
significant advantages. Firstly, it does not require annotations of sensitive
attributes in both testing and training data. This is more suitable for
real-life scenarios compared to existing methods that require annotations of
sensitive attributes at train time. Second, our approach exhibits a comparable
or better fairness-accuracy trade-off compared to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The DURel Annotation Tool: Human and Computational Measurement of
  Semantic Proximity, Sense Clusters and Semantic Change 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12664v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12664v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik Schlechtweg, Shafqat Mumtaz Virk, Pauline Sander, Emma Sköldberg, Lukas Theuer Linke, Tuo Zhang, Nina Tahmasebi, Jonas Kuhn, Sabine Schulte im Walde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the DURel tool that implements the annotation of semantic
proximity between uses of words into an online, open source interface. The tool
supports standardized human annotation as well as computational annotation,
building on recent advances with Word-in-Context models. Annotator judgments
are clustered with automatic graph clustering techniques and visualized for
analysis. This allows to measure word senses with simple and intuitive
micro-task judgments between use pairs, requiring minimal preparation efforts.
The tool offers additional functionalities to compare the agreement between
annotators to guarantee the inter-subjectivity of the obtained judgments and to
calculate summary statistics giving insights into sense frequency
distributions, semantic variation or changes of senses over time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MathGloss: Building mathematical glossaries from text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucy Horowitz, Valeria de Paiva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  MathGloss is a project to create a knowledge graph (KG) for undergraduate
mathematics from text, automatically, using modern natural language processing
(NLP) tools and resources already available on the web. MathGloss is a linked
database of undergraduate concepts in mathematics. So far, it combines five
resources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph
hosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses
at the University of Chicago, (iii) the syllabus of the French undergraduate
mathematics curriculum which includes hyperlinks to the automated theorem
prover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by
mathematicians, and (v) the nLab, a wiki for category theory also curated by
mathematicians. MathGloss's goal is to bring together resources for learning
mathematics and to allow every mathematician to tailor their learning to their
own preferences. Moreover, by organizing different resources for learning
undergraduate mathematics alongside those for learning formal mathematics, we
hope to make it easier for mathematicians and formal tools (theorem provers,
computer algebra systems, etc) experts to "understand" each other and break
down some of the barriers to formal math.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IMGTB: A Framework for Machine-Generated Text Detection Benchmarking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michal Spiegel, Dominik Macko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of large language models generating high quality texts, it is a
necessity to develop methods for detection of machine-generated text to avoid
harmful use or simply due to annotation purposes. It is, however, also
important to properly evaluate and compare such developed methods. Recently, a
few benchmarks have been proposed for this purpose; however, integration of
newest detection methods is rather challenging, since new methods appear each
month and provide slightly different evaluation pipelines. In this paper, we
present the IMGTB framework, which simplifies the benchmarking of
machine-generated text detection methods by easy integration of custom (new)
methods and evaluation datasets. Its configurability and flexibility makes
research and development of new detection methods easier, especially their
comparison to the existing state-of-the-art detectors. The default set of
analyses, metrics and visualizations offered by the tool follows the
established practices of machine-generated text detection benchmarking found in
state-of-the-art literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-Context Learning Functions with Varying Number of Minima 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12538v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12538v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Oniani, Yanshan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have proven effective at In-Context Learning
(ICL), an ability that allows them to create predictors from labeled examples.
Few studies have explored the interplay between ICL and specific properties of
functions it attempts to approximate. In our study, we use a formal framework
to explore ICL and propose a new task of approximating functions with varying
number of minima. We implement a method that allows for producing functions
with given inputs as minima. We find that increasing the number of minima
degrades ICL performance. At the same time, our evaluation shows that ICL
outperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster
than 2NN in all settings. We validate the findings through a set of few-shot
experiments across various hyperparameter configurations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Oasis: Data Curation and Assessment System for <span class="highlight-title">Pretrain</span>ing of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Zhou, Yubo Chen, Pengfei Cao, Kang Liu, Jun Zhao, Shengping Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data is one of the most critical elements in building a large language model.
However, existing systems either fail to customize a corpus curation pipeline
or neglect to leverage comprehensive corpus assessment for iterative
optimization of the curation. To this end, we present a pretraining corpus
curation and assessment platform called Oasis -- a one-stop system for data
quality improvement and quantification with user-friendly interactive
interfaces. Specifically, the interactive modular rule filter module can devise
customized rules according to explicit feedback. The debiased neural filter
module builds the quality classification dataset in a negative-centric manner
to remove the undesired bias. The adaptive document deduplication module could
execute large-scale deduplication with limited memory resources. These three
parts constitute the customized data curation module. And in the holistic data
assessment module, a corpus can be assessed in local and global views, with
three evaluation means including human, GPT-4, and heuristic metrics. We
exhibit a complete process to use Oasis for the curation and assessment of
pretraining data. In addition, an 800GB bilingual corpus curated by Oasis is
publicly released.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation Metrics of Language Generation Models for Synthetic Traffic
  Generation Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simone Filice, Jason Ingyu Choi, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many Natural Language Generation (NLG) tasks aim to generate a single output
text given an input prompt. Other settings require the generation of multiple
texts, e.g., for Synthetic Traffic Generation (STG). This generation task is
crucial for training and evaluating QA systems as well as conversational
agents, where the goal is to generate multiple questions or utterances
resembling the linguistic variability of real users. In this paper, we show
that common NLG metrics, like BLEU, are not suitable for evaluating STG. We
propose and evaluate several metrics designed to compare the generated traffic
to the distribution of real user texts. We validate our metrics with an
automatic procedure to verify whether they capture different types of quality
issues of generated data; we also run human annotations to verify the
correlation with human judgements. Experiments on three tasks, i.e., Shopping
Utterance Generation, Product Question Generation and Query Auto Completion,
demonstrate that our metrics are effective for evaluating STG tasks, and
improve the agreement with human judgement up to 20% with respect to common NLG
metrics. We believe these findings can pave the way towards better solutions
for estimating the representativeness of synthetic text data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multilingual Word Embeddings for Low-Resource Languages using Anchors
  and a Chain of Related Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12489v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12489v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Viktor Hangya, Silvia Severini, Radoslav Ralev, Alexander Fraser, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Very low-resource languages, having only a few million tokens worth of data,
are not well-supported by multilingual NLP approaches due to poor quality
cross-lingual word representations. Recent work showed that good cross-lingual
performance can be achieved if a source language is related to the low-resource
target language. However, not all language pairs are related. In this paper, we
propose to build multilingual word embeddings (MWEs) via a novel language
chain-based approach, that incorporates intermediate related languages to
bridge the gap between the distant source and target. We build MWEs one
language at a time by starting from the resource rich source and sequentially
adding each language in the chain till we reach the target. We extend a
semi-joint bilingual approach to multiple languages in order to eliminate the
main weakness of previous works, i.e., independently trained monolingual
embeddings, by anchoring the target language around the multilingual space. We
evaluate our method on bilingual lexicon induction for 4 language families,
involving 4 very low-resource (<5M tokens) and 4 moderately low-resource (<50M)
target languages, showing improved performance in both categories.
Additionally, our analysis reveals the importance of good quality embeddings
for intermediate languages as well as the importance of leveraging anchor
points from all languages in the multilingual space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the MRL 2023 workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speaker-Adapted End-to-End Visual Speech Recognition for Continuous
  Spanish 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Different studies have shown the importance of visual cues throughout the
speech perception process. In fact, the development of audiovisual approaches
has led to advances in the field of speech technologies. However, although
noticeable results have recently been achieved, visual speech recognition
remains an open research problem. It is a task in which, by dispensing with the
auditory sense, challenges such as visual ambiguities and the complexity of
modeling silence must be faced. Nonetheless, some of these challenges can be
alleviated when the problem is approached from a speaker-dependent perspective.
Thus, this paper studies, using the Spanish LIP-RTVE database, how the
estimation of specialized end-to-end systems for a specific person could affect
the quality of speech recognition. First, different adaptation strategies based
on the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention
architecture was used as a baseline throughout our experiments. Our findings
showed that a two-step fine-tuning process, where the VSR system is first
adapted to the task domain, provided significant improvements when the speaker
adaptation was addressed. Furthermore, results comparable to the current state
of the art were reached even when only a limited amount of data was available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Proceedings of IberSpeech 2022 (
  https://www.isca-speech.org/archive/iberspeech_2022/gimenogomez22_iberspeech.html
  )</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PhayaThai<span class="highlight-title">BERT</span>: Enhancing a <span class="highlight-title">Pretrain</span>ed Thai Language Model with
  Unassimilated Loanwords 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12475v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12475v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panyut Sriwirote, Jalinee Thapiang, Vasan Timtong, Attapol T. Rutherford
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While WangchanBERTa has become the de facto standard in transformer-based
Thai language modeling, it still has shortcomings in regard to the
understanding of foreign words, most notably English words, which are often
borrowed without orthographic assimilation into Thai in many contexts. We
identify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the
main source of these shortcomings. We then expand WangchanBERTa's vocabulary
via vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new
model using the expanded tokenizer, starting from WangchanBERTa's checkpoint,
on a new dataset that is larger than the one used to train WangchanBERTa. Our
results show that our new pretrained model, PhayaThaiBERT, outperforms
WangchanBERTa in many downstream tasks and datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CSMeD: Bridging the <span class="highlight-title">Dataset</span> Gap in Automated Citation Screening for
  Systematic Literature <span class="highlight-title">Review</span>s <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wojciech Kusa, Oscar E. Mendoza, Matthias Samwald, Petr Knoth, Allan Hanbury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Systematic literature reviews (SLRs) play an essential role in summarising,
synthesising and validating scientific evidence. In recent years, there has
been a growing interest in using machine learning techniques to automate the
identification of relevant studies for SLRs. However, the lack of standardised
evaluation datasets makes comparing the performance of such automated
literature screening systems difficult. In this paper, we analyse the citation
screening evaluation datasets, revealing that many of the available datasets
are either too small, suffer from data leakage or have limited applicability to
systems treating automated literature screening as a classification task, as
opposed to, for example, a retrieval or question-answering task. To address
these challenges, we introduce CSMeD, a meta-dataset consolidating nine
publicly released collections, providing unified access to 325 SLRs from the
fields of medicine and computer science. CSMeD serves as a comprehensive
resource for training and evaluating the performance of automated citation
screening models. Additionally, we introduce CSMeD-FT, a new dataset designed
explicitly for evaluating the full text publication screening task. To
demonstrate the utility of CSMeD, we conduct experiments and establish
baselines on new datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NeurIPS 2023 Datasets and Benchmarks Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analysis of Visual Features for Continuous Lipreading in Spanish 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12468v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12468v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  During a conversation, our brain is responsible for combining information
obtained from multiple senses in order to improve our ability to understand the
message we are perceiving. Different studies have shown the importance of
presenting visual information in these situations. Nevertheless, lipreading is
a complex task whose objective is to interpret speech when audio is not
available. By dispensing with a sense as crucial as hearing, it will be
necessary to be aware of the challenge that this lack presents. In this paper,
we propose an analysis of different speech visual features with the intention
of identifying which of them is the best approach to capture the nature of lip
movements for natural Spanish and, in this way, dealing with the automatic
visual speech recognition task. In order to estimate our system, we present an
audiovisual corpus compiled from a subset of the RTVE database, which has been
used in the Albayz\'in evaluations. We employ a traditional system based on
Hidden Markov Models with Gaussian Mixture Models. Results show that, although
the task is difficult, in restricted conditions we obtain recognition results
which determine that using eigenlips in combination with deep features is the
best visual approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Proceedings of IberSpeech 2020 (
  https://www.isca-speech.org/archive/iberspeech_2021/gimenogomez21_iberspeech.html
  )</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild <span class="chip">LREC 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Gimeno-Gómez, Carlos-D. Martínez-Hinarejos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech is considered as a multi-modal process where hearing and vision are
two fundamentals pillars. In fact, several studies have demonstrated that the
robustness of Automatic Speech Recognition systems can be improved when audio
and visual cues are combined to represent the nature of speech. In addition,
Visual Speech Recognition, an open research problem whose purpose is to
interpret speech by reading the lips of the speaker, has been a focus of
interest in the last decades. Nevertheless, in order to estimate these systems
in the currently Deep Learning era, large-scale databases are required. On the
other hand, while most of these databases are dedicated to English, other
languages lack sufficient resources. Thus, this paper presents a
semi-automatically annotated audiovisual database to deal with unconstrained
natural Spanish, providing 13 hours of data extracted from Spanish television.
Furthermore, baseline results for both speaker-dependent and
speaker-independent scenarios are reported using Hidden Markov Models, a
traditional paradigm that has been widely used in the field of Speech
Technologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Proceedings of LREC 2022 (
  https://aclanthology.org/2022.lrec-1.294 )</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Far Have We Gone in Vulnerability Detection Using Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Gao, Hao Wang, Yuchen Zhou, Wenyu Zhu, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As software becomes increasingly complex and prone to vulnerabilities,
automated vulnerability detection is critically important, yet challenging.
Given the significant successes of Large Language Models (LLMs) in various
tasks, there is growing anticipation of their efficacy in vulnerability
detection. However, a quantitative understanding of their potential in
vulnerability detection is still missing. To bridge this gap, we introduce a
comprehensive vulnerability benchmark VulBench. This benchmark aggregates
high-quality data from a wide range of CTF (Capture-the-Flag) challenges and
real-world applications, with annotations for each vulnerable function
detailing the vulnerability type and its root cause. Through our experiments
encompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models
and static analyzers, we find that several LLMs outperform traditional deep
learning approaches in vulnerability detection, revealing an untapped potential
in LLMs. This work contributes to the understanding and utilization of LLMs for
enhanced software security.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Visual Analytics for Generative <span class="highlight-title">Transformer</span> Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12418v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12418v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raymond Li, Ruixin Yang, Wen Xiao, Ahmed AbuRaed, Gabriel Murray, Giuseppe Carenini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While transformer-based models have achieved state-of-the-art results in a
variety of classification and generation tasks, their black-box nature makes
them challenging for interpretability. In this work, we present a novel visual
analytical framework to support the analysis of transformer-based generative
networks. In contrast to previous work, which has mainly focused on
encoder-based models, our framework is one of the first dedicated to supporting
the analysis of transformer-based encoder-decoder models and decoder-only
models for generative and classification tasks. Hence, we offer an intuitive
overview that allows the user to explore different facets of the model through
interactive visualization. To demonstrate the feasibility and usefulness of our
framework, we present three detailed case studies based on real-world NLP
research problems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages (reference excluded), 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ nach0: Multimodal Natural and Chemical Languages Foundation Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12410v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12410v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, Anthony Costa, Alex Aliper, Alex Zhavoronkov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have substantially driven scientific progress in
various domains, and many papers have demonstrated their ability to tackle
complex problems with creative solutions. Our paper introduces a new foundation
model, nach0, capable of solving various chemical and biological tasks:
biomedical question answering, named entity recognition, molecular generation,
molecular synthesis, attributes prediction, and others. nach0 is a multi-domain
and multi-task encoder-decoder LLM pre-trained on unlabeled text from
scientific literature, patents, and molecule strings to incorporate a range of
chemical and linguistic knowledge. We employed instruction tuning, where
specific task-related instructions are utilized to fine-tune nach0 for the
final set of tasks. To train nach0 effectively, we leverage the NeMo framework,
enabling efficient parallel optimization of both base and large model versions.
Extensive experiments demonstrate that our model outperforms state-of-the-art
baselines on single-domain and cross-domain tasks. Furthermore, it can generate
high-quality outputs in molecular and textual formats, showcasing its
effectiveness in multi-domain setups.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to Nature Communications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian
  Local Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Genta Indra Winata, Pascale Fung, Ayu Purwarianti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Significant progress has been made on Indonesian NLP. Nevertheless,
exploration of the code-mixing phenomenon in Indonesian is limited, despite
many languages being frequently mixed with Indonesian in daily conversation. In
this work, we explore code-mixing in Indonesian with four embedded languages,
i.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a
framework to evaluate and improve the code-mixing robustness. Our analysis
shows that the pre-training corpus bias affects the model's ability to better
handle Indonesian-English code-mixing when compared to other local languages,
despite having higher language diversity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inter<span class="highlight-title">Prompt</span>: Interpretable <span class="highlight-title">Prompt</span>ing for Interrelated Interpersonal Risk
  Factors in Reddit Posts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12404v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12404v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        MSVPJ Sathvik, Surjodeep Sarkar, Chandni Saxena, Sunghwan Sohn, Muskan Garg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mental health professionals and clinicians have observed the upsurge of
mental disorders due to Interpersonal Risk Factors (IRFs). To simulate the
human-in-the-loop triaging scenario for early detection of mental health
disorders, we recognized textual indications to ascertain these IRFs : Thwarted
Belongingness (TBe) and Perceived Burdensomeness (PBu) within personal
narratives. In light of this, we use N-shot learning with GPT-3 model on the
IRF dataset, and underscored the importance of fine-tuning GPT-3 model to
incorporate the context-specific sensitivity and the interconnectedness of
textual cues that represent both IRFs.
  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method
to boost the attention mechanism by fine-tuning the GPT-3 model. This allows a
more sophisticated level of language modification by adjusting the pre-trained
weights. Our model learns to detect usual patterns and underlying connections
across both the IRFs, which leads to better system-level explainability and
trustworthiness. The results of our research demonstrate that all four variants
of GPT-3 model, when fine-tuned with InterPrompt, perform considerably better
as compared to the baseline methods, both in terms of classification and
explanation generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Graph Meets Large Language Model: Progress and Future
  Directions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12399v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12399v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, Jeffrey Xu Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph plays a significant role in representing and analyzing complex
relationships in real-world applications such as citation networks, social
networks, and biological data. Recently, Large Language Models (LLMs), which
have achieved tremendous success in various domains, have also been leveraged
in graph-related tasks to surpass traditional Graph Neural Networks (GNNs)
based methods and yield state-of-the-art performance. In this survey, we first
present a comprehensive review and analysis of existing methods that integrate
LLMs with graphs. First of all, we propose a new taxonomy, which organizes
existing methods into three categories based on the role (i.e., enhancer,
predictor, and alignment component) played by LLMs in graph-related tasks. Then
we systematically survey the representative methods along the three categories
of the taxonomy. Finally, we discuss the remaining limitations of existing
studies and highlight promising avenues for future research. The relevant
papers are summarized and will be consistently updated at:
https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress; 13 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Problems of Non-equivalent Words in Technical Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12395v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12395v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Ibrahim Qani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Translating words which do not have equivalent in target language is not easy
and finding proper equivalent of those words are very important to render
correctly and understandably, the article defines some thoughts and ideas of
scientists on the common problems of non-equivalent words from English to
Russian language and includes English and Russian examples and ideas of certain
scientist. The English language is worldwide spoken and there are 1.35 billion
English speakers and over 258 million Russian speakers according to the 2021s
statistics. Inevitably, these billions of speakers around the world have
connection and they may have deal in different criteria. In order to understand
one another they need to have a pure and fully-understood language. These pure
languages understanding directly relates to translation knowledge where
linguists and translators need to work and research to eradicate
misunderstanding. Misunderstandings mostly appear in non-equivalent words
because there are different local and internal words like food, garment,
cultural and traditional words and others in every notion. Truly, most of these
words do not have equivalent in the target language and these words need to be
worked and find their equivalent in the target language to fully understand the
both languages. However, some of these non-equivalent words are already
professionally rendered to the target language but still there many other words
to be rendered. Hence, this research paper includes different ways and rules of
rendering non-equivalent words from source language to the target language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Obscure Limitation of Modular Multilingual Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Ayu Purwarianti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We expose the limitation of modular multilingual language models (MLMs) in
multilingual inference scenarios with unknown languages. Existing evaluations
of modular MLMs exclude the involvement of language identification (LID)
modules, which obscures the performance of real-case multilingual scenarios of
modular MLMs. In this work, we showcase the effect of adding LID on the
multilingual evaluation of modular MLMs and provide discussions for closing the
performance gap of caused by the pipelined approach of LID and modular MLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Turing: A Comparative Analysis of Approaches for Detecting
  Machine-Generated Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12373v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12373v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Farid Adilazuarda, Nikolaos Nektarios Arkoulis, Oleksii Chumakov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Significant progress has been made on text generation by pre-trained language
models (PLMs), yet distinguishing between human and machine-generated text
poses an escalating challenge. This paper offers an in-depth evaluation of
three distinct methods used to address this task: traditional shallow learning,
Language Model (LM) fine-tuning, and Multilingual Model fine-tuning. These
approaches are rigorously tested on a wide range of machine-generated texts,
providing a benchmark of their competence in distinguishing between
human-authored and machine-authored linguistic constructs. The results reveal
considerable differences in performance across methods, thus emphasizing the
continued need for advancement in this crucial area of NLP. This study offers
valuable insights and paves the way for future research aimed at creating
robust and highly discriminative models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Utilizing Language Models for Tour Itinerary Recommendation <span class="chip">IJCAI 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ngai Lam Ho, Kwan Hui Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tour itinerary recommendation involves planning a sequence of relevant
Point-of-Interest (POIs), which combines challenges from the fields of both
Operations Research (OR) and Recommendation Systems (RS). As an OR problem,
there is the need to maximize a certain utility (e.g., popularity of POIs in
the tour) while adhering to some constraints (e.g., maximum time for the tour).
As a RS problem, it is heavily related to problem or filtering or ranking a
subset of POIs that are relevant to a user and recommending it as part of an
itinerary. In this paper, we explore the use of language models for the task of
tour itinerary recommendation and planning. This task has the unique
requirement of recommending personalized POIs relevant to users and planning
these POIs as an itinerary that satisfies various constraints. We discuss some
approaches in this area, such as using word embedding techniques like Word2Vec
and GloVe for learning POI embeddings and transformer-based techniques like
BERT for generating
  itineraries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PMAI23 @IJCAI 2023 2nd International Workshop on Process Management
  in the AI era</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing <span class="highlight-title">Transformer</span> Architecture in Long-Context Large Language
  Models: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Huang, Jingwei Xu, Zixu Jiang, Junyu Lai, Zenan Li, Yuan Yao, Taolue Chen, Lijuan Yang, Zhou Xin, Xiaoxing Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the bomb ignited by ChatGPT, Transformer-based Large Language Models
(LLMs) have paved a revolutionary path toward Artificial General Intelligence
(AGI) and have been applied in diverse areas as knowledge bases, human
interfaces, and dynamic agents. However, a prevailing limitation exists: many
current LLMs, constrained by resources, are primarily pre-trained on shorter
texts, rendering them less effective for longer-context prompts, commonly
encountered in real-world settings. In this paper, we present a comprehensive
survey focusing on the advancement of model architecture in Transformer-based
LLMs to optimize long-context capabilities across all stages from pre-training
to inference. We firstly delineate and analyze the problems of handling
long-context input and output with the current Transformer-based models. Then,
we mainly offer a holistic taxonomy to navigate the landscape of Transformer
upgrades on architecture to solve these problems. Afterward, we provide the
investigation on wildly used evaluation necessities tailored for long-context
LLMs, including datasets, metrics, and baseline models, as well as some amazing
optimization toolkits like libraries, systems, and compilers to augment LLMs'
efficiency and efficacy across different stages. Finally, we further discuss
the predominant challenges and potential avenues for future research in this
domain. Additionally, we have established a repository where we curate relevant
literature with real-time updates at
https://github.com/Strivin0311/long-llms-learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 3 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do Smaller Language Models Answer Contextualised Questions Through
  Memorisation Or Generalisation? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Hartill, Joshua Bensemann, Michael Witbrock, Patricia J. Riddle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A distinction is often drawn between a model's ability to predict a label for
an evaluation sample that is directly memorised from highly similar training
samples versus an ability to predict the label via some method of
generalisation. In the context of using Language Models for question-answering,
discussion continues to occur as to the extent to which questions are answered
through memorisation. We consider this issue for questions that would ideally
be answered through reasoning over an associated context. We propose a method
of identifying evaluation samples for which it is very unlikely our model would
have memorised the answers. Our method is based on semantic similarity of input
tokens and label tokens between training and evaluation samples. We show that
our method offers advantages upon some prior approaches in that it is able to
surface evaluation-train pairs that have overlap in either contiguous or
discontiguous sequences of tokens. We use this method to identify unmemorisable
subsets of our evaluation datasets. We train two Language Models in a multitask
fashion whereby the second model differs from the first only in that it has two
additional datasets added to the training regime that are designed to impart
simple numerical reasoning strategies of a sort known to improve performance on
some of our evaluation datasets but not on others. We then show that there is
performance improvement between the two models on the unmemorisable subsets of
the evaluation datasets that were expected to benefit from the additional
training datasets. Specifically, performance on unmemorisable subsets of two of
our evaluation datasets, DROP and ROPES significantly improves by 9.0%, and
25.7% respectively while other evaluation datasets have no significant change
in performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling Political Orientation of Social Media Posts: An Extended
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12323v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12323v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sadia Kamal, Brenner Little, Jade Gullic, Trevor Harms, Kristin Olofsson, Arunkumar Bagavathi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing machine learning models to characterize political polarization on
online social media presents significant challenges. These challenges mainly
stem from various factors such as the lack of annotated data, presence of noise
in social media datasets, and the sheer volume of data. The common research
practice typically examines the biased structure of online user communities for
a given topic or qualitatively measuring the impacts of polarized topics on
social media. However, there is limited work focusing on analyzing polarization
at the ground-level, specifically in the social media posts themselves. Such
existing analysis heavily relies on annotated data, which often requires
laborious human labeling, offers labels only to specific problems, and lacks
the ability to determine the near-future bias state of a social media
conversations. Understanding the degree of political orientation conveyed in
social media posts is crucial for quantifying the bias of online user
communities and investigating the spread of polarized content. In this work, we
first introduce two heuristic methods that leverage on news media bias and post
content to label social media posts. Next, we compare the efficacy and quality
of heuristically labeled dataset with a randomly sampled human-annotated
dataset. Additionally, we demonstrate that current machine learning models can
exhibit improved performance in predicting political orientation of social
media posts, employing both traditional supervised learning and few-shot
learning setups. We conduct experiments using the proposed heuristic methods
and machine learning approaches to predict the political orientation of posts
collected from two social media forums with diverse political ideologies: Gab
and Twitter.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Academic<span class="highlight-title">GPT</span>: Empowering Academic Research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12315v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12315v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shufa Wei, Xiaolong Xu, Xianbiao Qi, Xi Yin, Jun Xia, Jingyi Ren, Peijun Tang, Yuxiang Zhong, Yihao Chen, Xiaoqin Ren, Yuxin Liang, Liankai Huang, Kai Xie, Weikang Gui, Wei Tan, Shuanglong Sun, Yongquan Hu, Qinxian Liu, Nanjin Li, Chihao Dai, Lihua Wang, Xiaohui Liu, Lei Zhang, Yutao Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated exceptional capabilities
across various natural language processing tasks. Yet, many of these advanced
LLMs are tailored for broad, general-purpose applications. In this technical
report, we introduce AcademicGPT, designed specifically to empower academic
research. AcademicGPT is a continual training model derived from LLaMA2-70B.
Our training corpus mainly consists of academic papers, thesis, content from
some academic domain, high-quality Chinese data and others. While it may not be
extensive in data scale, AcademicGPT marks our initial venture into a
domain-specific GPT tailored for research area. We evaluate AcademicGPT on
several established public benchmarks such as MMLU and CEval, as well as on
some specialized academic benchmarks like PubMedQA, SCIEval, and our
newly-created ComputerScienceQA, to demonstrate its ability from general
knowledge ability, to Chinese ability, and to academic ability. Building upon
AcademicGPT's foundation model, we also developed several applications catered
to the academic area, including General Academic Question Answering,
AI-assisted Paper Reading, Paper Review, and AI-assisted Title and Abstract
Generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report. arXiv admin note: text overlap with
  arXiv:2310.12081, arXiv:2310.10053 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Noise in <span class="highlight-title">Relation</span> Classification <span class="highlight-title">Dataset</span> TACRED: Characterization and
  Reduction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akshay Parekh, Ashish Anand, Amit Awekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The overarching objective of this paper is two-fold. First, to explore
model-based approaches to characterize the primary cause of the noise. in the
RE dataset TACRED Second, to identify the potentially noisy instances. Towards
the first objective, we analyze predictions and performance of state-of-the-art
(SOTA) models to identify the root cause of noise in the dataset. Our analysis
of TACRED shows that the majority of the noise in the dataset originates from
the instances labeled as no-relation which are negative examples. For the
second objective, we explore two nearest-neighbor-based strategies to
automatically identify potentially noisy examples for elimination and
reannotation. Our first strategy, referred to as Intrinsic Strategy (IS), is
based on the assumption that positive examples are clean. Thus, we have used
false-negative predictions to identify noisy negative examples. Whereas, our
second approach, referred to as Extrinsic Strategy, is based on using a clean
subset of the dataset to identify potentially noisy negative examples. Finally,
we retrained the SOTA models on the eliminated and reannotated dataset. Our
empirical results based on two SOTA models trained on TACRED-E following the IS
show an average 4% F1-score improvement, whereas reannotation (TACRED-R) does
not improve the original results. However, following ES, SOTA models show the
average F1-score improvement of 3.8% and 4.4% when trained on respective
eliminated (TACRED-EN) and reannotated (TACRED-RN) datasets respectively. We
further extended the ES for cleaning positive examples as well, which resulted
in an average performance improvement of 5.8% and 5.6% for the eliminated
(TACRED-ENP) and reannotated (TACRED-RNP) datasets respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for
  Interdisciplinary Science 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12289v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12289v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sai Munikoti, Anurag Acharya, Sridevi Wagle, Sameera Horawalavithana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models record impressive performance on many natural language
processing tasks. However, their knowledge capacity is limited to the
pretraining corpus. Retrieval augmentation offers an effective solution by
retrieving context from external knowledge sources to complement the language
model. However, existing retrieval augmentation techniques ignore the
structural relationships between these documents. Furthermore, retrieval models
are not explored much in scientific tasks, especially in regard to the
faithfulness of retrieved documents. In this paper, we propose a novel
structure-aware retrieval augmented language model that accommodates document
structure during retrieval augmentation. We create a heterogeneous document
graph capturing multiple types of relationships (e.g., citation, co-authorship,
etc.) that connect documents from more than 15 scientific disciplines (e.g.,
Physics, Medicine, Chemistry, etc.). We train a graph neural network on the
curated document graph to act as a structural encoder for the corresponding
passages retrieved during the model pretraining. Particularly, along with text
embeddings of the retrieved passages, we obtain structural embeddings of the
documents (passages) and fuse them together before feeding them to the language
model. We evaluate our model extensively on various scientific benchmarks that
include science question-answering and scientific document classification
tasks. Experimental results demonstrate that structure-aware retrieval improves
retrieving more coherent, faithful and contextually relevant passages, while
showing a comparable performance in the overall accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enabling On-Device Large Language Model Personalization with
  <span class="highlight-title">Self-Supervised</span> Data Selection and Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12275v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12275v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiyang Qin, Jun Xia, Zhenge Jia, Meng Jiang, Ahmed Abbasi, Peipei Zhou, Jingtong Hu, Yiyu Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  After a large language model (LLM) is deployed on edge devices, it is
desirable for these devices to learn from user-generated conversation data to
generate user-specific and personalized responses in real-time. However,
user-generated data usually contains sensitive and private information, and
uploading such data to the cloud for annotation is not preferred if not
prohibited. While it is possible to obtain annotation locally by directly
asking users to provide preferred responses, such annotations have to be sparse
to not affect user experience. In addition, the storage of edge devices is
usually too limited to enable large-scale fine-tuning with full user-generated
data. It remains an open question how to enable on-device LLM personalization,
considering sparse annotation and limited on-device storage. In this paper, we
propose a novel framework to select and store the most representative data
online in a self-supervised way. Such data has a small memory footprint and
allows infrequent requests of user annotations for further fine-tuning. To
enhance fine-tuning quality, multiple semantically similar pairs of question
texts and expected responses are generated using the LLM. Our experiments show
that the proposed framework achieves the best user-specific content-generating
capability (accuracy) and fine-tuning speed (performance) compared with vanilla
baselines. To the best of our knowledge, this is the very first on-device LLM
personalization framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Banach-Tarski Embeddings and <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09387v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09387v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Maher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a new construction of embeddings of arbitrary recursive data
structures into high dimensional vectors. These embeddings provide an
interpretable model for the latent state vectors of transformers. We
demonstrate that these embeddings can be decoded to the original data structure
when the embedding dimension is sufficiently large. This decoding algorithm has
a natural implementation as a transformer. We also show that these embedding
vectors can be manipulated directly to perform computations on the underlying
data without decoding. As an example we present an algorithm that constructs
the embedded parse tree of an embedded token sequence using only vector
operations in embedding space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 7 figures. v2: Fixed order of matrix multiplication in
  section 2.4</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Editing Personality for LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.02168v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.02168v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengyu Mao, Ningyu Zhang, Xiaohan Wang, Mengru Wang, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces an innovative task focused on editing the personality
traits of Large Language Models (LLMs). This task seeks to adjust the models'
responses to opinion-related questions on specified topics since an
individual's personality often manifests in the form of their expressed
opinions, thereby showcasing different personality traits. Specifically, we
construct a new benchmark dataset PersonalityEdit to address this task. Drawing
on the theory in Social Psychology, we isolate three representative traits,
namely Neuroticism, Extraversion, and Agreeableness, as the foundation for our
benchmark. We then gather data using GPT-4, generating responses that not only
align with a specified topic but also embody the targeted personality trait. We
conduct comprehensive experiments involving various baselines and discuss the
representation of personality behavior in LLMs. Our intriguing findings uncover
potential challenges of the proposed task, illustrating several remaining
issues. We anticipate that our work can provide the NLP community with
insights. Code and datasets will be released at
https://github.com/zjunlp/EasyEdit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress, add more experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling the Pitfalls of Knowledge Editing for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.02129v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.02129v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang, Xi Chen, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the cost associated with fine-tuning Large Language Models (LLMs)
continues to rise, recent research efforts have pivoted towards developing
methodologies to edit implicit knowledge embedded within LLMs. Yet, there's
still a dark cloud lingering overhead -- will knowledge editing trigger
butterfly effect? since it is still unclear whether knowledge editing might
introduce side effects that pose potential risks or not. This paper pioneers
the investigation into the potential pitfalls associated with knowledge editing
for LLMs. To achieve this, we introduce new benchmark datasets and propose
innovative evaluation metrics. Our results underline two pivotal concerns: (1)
Knowledge Conflict: Editing groups of facts that logically clash can magnify
the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)
Knowledge Distortion: Altering parameters with the aim of editing factual
knowledge can irrevocably warp the innate knowledge structure of LLMs.
Experimental results vividly demonstrate that knowledge editing might
inadvertently cast a shadow of unintended consequences on LLMs, which warrant
attention and efforts for future works. Code is available at
https://github.com/zjunlp/PitfallsKnowledgeEditing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress, add more experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Relphormer: <span class="highlight-title">Relation</span>al Graph <span class="highlight-title">Transformer</span> for Knowledge Graph
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2205.10852v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2205.10852v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Bi, Siyuan Cheng, Jing Chen, Xiaozhuan Liang, Feiyu Xiong, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers have achieved remarkable performance in widespread fields,
including natural language processing, computer vision and graph mining.
However, vanilla Transformer architectures have not yielded promising
improvements in the Knowledge Graph (KG) representations, where the
translational distance paradigm dominates this area. Note that vanilla
Transformer architectures struggle to capture the intrinsically heterogeneous
structural and semantic information of knowledge graphs. To this end, we
propose a new variant of Transformer for knowledge graph representations dubbed
Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample
contextualized sub-graph sequences as the input to alleviate the heterogeneity
issue. We propose a novel structure-enhanced self-attention mechanism to encode
the relational information and keep the semantic information within entities
and relations. Moreover, we utilize masked knowledge modeling for general
knowledge graph representation learning, which can be applied to various
KG-based tasks including knowledge graph completion, question answering, and
recommendation. Experimental results on six datasets show that Relphormer can
obtain better performance compared with baselines. Code is available in
https://github.com/zjunlp/Relphormer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Neurocomputing 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by
  Whispering to Chat<span class="highlight-title">GPT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.17103v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.17103v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Le Zhuo, Ruibin Yuan, Jiahao Pan, Yinghao Ma, Yizhi LI, Ge Zhang, Si Liu, Roger Dannenberg, Jie Fu, Chenghua Lin, Emmanouil Benetos, Wenhu Chen, Wei Xue, Yike Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic
lyrics transcription method achieving state-of-the-art performance on various
lyrics transcription datasets, even in challenging genres such as rock and
metal. Our novel, training-free approach utilizes Whisper, a weakly supervised
robust speech recognition model, and GPT-4, today's most performant chat-based
large language model. In the proposed method, Whisper functions as the "ear" by
transcribing the audio, while GPT-4 serves as the "brain," acting as an
annotator with a strong performance for contextualized output selection and
correction. Our experiments show that LyricWhiz significantly reduces Word
Error Rate compared to existing methods in English and can effectively
transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to
create the first publicly available, large-scale, multilingual lyrics
transcription dataset with a CC-BY-NC-SA copyright license, based on
MTG-Jamendo, and offer a human-annotated subset for noise level estimation and
evaluation. We anticipate that our proposed method and dataset will advance the
development of multilingual lyrics transcription, a challenging and emerging
task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 2 figures, 5 tables, accepted by ISMIR 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Influencer Videos: Unboxing the Mystique 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2012.12311v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2012.12311v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prashant Rajaram, Puneet Manchanda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Influencer marketing has become a very popular tool to reach customers.
Despite the rapid growth in influencer videos, there has been little research
on the effectiveness of their constituent features in explaining video
engagement. We study YouTube influencers and analyze their unstructured video
data across text, audio and images using an "interpretable deep learning"
framework that accomplishes both goals of prediction and interpretation. Our
prediction-based approach analyzes unstructured data and finds that "what is
said" in words (text) is more influential than "how it is said" in imagery
(images) or acoustics (audio). Our novel interpretation-based approach is
implemented after completion of model prediction by analyzing the same source
of unstructured data to measure importance attributed to the video features. We
eliminate several spurious relationships in two steps, identifying a subset of
relationships which are confirmed using theory. We uncover novel findings that
establish distinct associations for measures of shallow and deep engagement
based on the dual-system framework of human thinking. Our approach is validated
using simulated data, and we discuss the learnings from our findings for
influencers and brands.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>45 pages, Online Appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open Sesame! Universal Black Box Jailbreaking of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.01446v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.01446v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raz Lapid, Ron Langberg, Moshe Sipper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), designed to provide helpful and safe responses,
often rely on alignment techniques to align with user intent and social
guidelines. Unfortunately, this alignment can be exploited by malicious actors
seeking to manipulate an LLM's outputs for unintended purposes. In this paper
we introduce a novel approach that employs a genetic algorithm (GA) to
manipulate LLMs when model architecture and parameters are inaccessible. The GA
attack works by optimizing a universal adversarial prompt that -- when combined
with a user's query -- disrupts the attacked model's alignment, resulting in
unintended and potentially harmful outputs. Our novel approach systematically
reveals a model's limitations and vulnerabilities by uncovering instances where
its responses deviate from expected behavior. Through extensive experiments we
demonstrate the efficacy of our technique, thus contributing to the ongoing
discussion on responsible AI development by providing a diagnostic tool for
evaluating and enhancing alignment of LLMs with human intent. To our knowledge
this is the first automated universal black box jailbreak attack.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harnessing the Power of Large Language Models for Empathetic Response
  Generation: Empirical Investigations and Improvements <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.05140v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.05140v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushan Qian, Wei-Nan Zhang, Ting Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Empathetic dialogue is an indispensable part of building harmonious social
relationships and contributes to the development of a helpful AI. Previous
approaches are mainly based on fine small-scale language models. With the
advent of ChatGPT, the application effect of large language models (LLMs) in
this field has attracted great attention. This work empirically investigates
the performance of LLMs in generating empathetic responses and proposes three
improvement methods of semantically similar in-context learning, two-stage
interactive generation, and combination with the knowledge base. Extensive
experiments show that LLMs can significantly benefit from our proposed methods
and is able to achieve state-of-the-art performance in both automatic and human
evaluations. Additionally, we explore the possibility of GPT-4 simulating human
evaluators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>the Findings of EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BigTranslate: Augmenting Large Language Models with Multilingual
  Translation Capability over 100 Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.18098v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.18098v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wen Yang, Chong Li, Jiajun Zhang, Chengqing Zong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate promising translation performance
among various natural languages. However, many LLMs especially the open-sourced
ones, such as BLOOM and LLaMA, are English-dominant and support only dozens of
natural languages, making the potential of LLMs on language translation less
explored. In this work, we present BigTranslate which adapts LLaMA that covers
only 20 languages and enhances it with multilingual translation capability on
more than 100 languages. BigTranslate is built upon LLaMA-13B and it is
optimized in three steps. First, we continue training LLaMA with massive
Chinese monolingual data. Second, we continue training the model with a
large-scale parallel dataset that covers 102 natural languages. Third, we
instruct-tune the foundation model with multilingual translation instructions,
leading to our BigTranslate model. The preliminary experiments on multilingual
translation show that BigTranslate performs comparably with ChatGPT and Google
Translate in many languages and even outperforms ChatGPT in 8 language pairs.
We release the BigTranslate model and hope it can advance the research
progress.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures. Our model is available at
  https://github.com/ZNLP/BigTranslate</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unified Segment-to-Segment Framework for Simultaneous Sequence
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.17940v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.17940v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaolei Zhang, Yang Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simultaneous sequence generation is a pivotal task for real-time scenarios,
such as streaming speech recognition, simultaneous machine translation and
simultaneous speech translation, where the target sequence is generated while
receiving the source sequence. The crux of achieving high-quality generation
with low latency lies in identifying the optimal moments for generating,
accomplished by learning a mapping between the source and target sequences.
However, existing methods often rely on task-specific heuristics for different
sequence types, limiting the model's capacity to adaptively learn the
source-target mapping and hindering the exploration of multi-task learning for
various simultaneous tasks. In this paper, we propose a unified
segment-to-segment framework (Seg2Seg) for simultaneous sequence generation,
which learns the mapping in an adaptive and unified manner. During the process
of simultaneous generation, the model alternates between waiting for a source
segment and generating a target segment, making the segment serve as the
natural bridge between the source and target. To accomplish this, Seg2Seg
introduces a latent segment as the pivot between source to target and explores
all potential source-target mappings via the proposed expectation training,
thereby learning the optimal moments for generating. Experiments on multiple
simultaneous generation tasks demonstrate that Seg2Seg achieves
state-of-the-art performance and exhibits better generality across various
tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Grammatical errors prevent the article from being indexed. This is
  not a problem that can be solved by replacing a new version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personas as a Way to Model Truthfulness in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.18168v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.18168v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung Kim, He He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are trained on vast amounts of text from the
internet, which contains both factual and misleading information about the
world. Can language models discern truth from falsehood in this contradicting
data? Expanding on the view that LLMs can model different communicative agents,
we present the persona hypothesis: LLMs can cluster agents into personas using
common features of their generations. For instance, a truthful persona is a
group of agents that are likely to produce truthful text and that share similar
features like formal writing styles and scientific references. By modeling this
persona, LLMs can generalize truthfulness beyond the specific contexts in which
each agent generated the training text. For example, the model can infer that
the agent ``Wikipedia'' will behave truthfully on topics that were only
generated by ``Science'' because they both belong to the truthful persona. We
show evidence for the persona hypothesis via two observations: (1) we can probe
whether a model's answer will be truthful before it is generated; (2)
finetuning a model on a set of facts improves its truthfulness on unseen
topics. Next, using arithmetics as a synthetic environment, we show that
language models can separate true and false statements, and generalize
truthfulness across agents; but only if agents in the training data share a
truthful generative process that enables the creation of a truthful persona.
Overall, our findings suggest that models can exploit hierarchical structures
in the data to learn abstract concepts like truthfulness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07161v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07161v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Shuo Han, Yunyang Zeng, Ankit Shah, Bhiksha Raj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,
the complexities introduced by acoustic transformations merit rigorous
analysis. This research, rooted in the exploration of proprietary sender-side
denoising effects, meticulously evaluates platforms such as Google Meets and
Zoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,
ensuring a structured examination tailored to various denoising settings and
receiver interfaces. A methodological novelty is introduced via the Oaxaca
decomposition, traditionally an econometric tool, repurposed herein to analyze
acoustic-phonetic perturbations within VoIP systems. To further ground the
implications of these transformations, psychoacoustic metrics, specifically
PESQ and STOI, were harnessed to furnish a comprehensive understanding of
speech alterations. Cumulatively, the insights garnered underscore the
intricate landscape of VoIP-influenced acoustic dynamics. In addition to the
primary findings, a multitude of metrics are reported, extending the research
purview. Moreover, out-of-domain benchmarking for both time and time-frequency
domain speech enhancement models is included, thereby enhancing the depth and
applicability of this inquiry. Repository:
github.com/deepology/VoIP-DNS-Challenge
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Systematic <span class="highlight-title">Review</span> of Aspect-based Sentiment Analysis (ABSA): Domains,
  Methods, and Trends 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10777v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10777v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Cathy Hua, Paul Denny, Katerina Taskova, Jörg Wicker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment
analysis (SA) that identifies aspects and the associated opinions from a given
text. In the digital era, ABSA gained increasing popularity and applications in
mining opinionated text data to obtain insights and support decisions. ABSA
research employs linguistic, statistical, and machine-learning approaches and
utilises resources such as labelled datasets, aspect and sentiment lexicons and
ontology. By its nature, ABSA is domain-dependent and can be sensitive to the
impact of misalignment between the resource and application domains. However,
to our knowledge, this topic has not been explored by the existing ABSA
literature reviews. In this paper, we present a Systematic Literature Review
(SLR) of ABSA studies with a focus on the research application domain, dataset
domain, and the research methods to examine their relationships and identify
trends over time. Our results suggest a number of potential systemic issues in
the ABSA research literature, including the predominance of the
``product/service review'' dataset domain among the majority of studies that
did not have a specific research application domain, coupled with the
prevalence of dataset-reliant methods such as supervised machine learning. This
review makes a number of unique contributions to the ABSA research field: 1) To
our knowledge, it is the first SLR that links the research domain, dataset
domain, and research method through a systematic perspective; 2) it is one of
the largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191
search results without time constraint; and 3) our review methodology adopted
an innovative automatic filtering process based on PDF-mining, which enhanced
screening quality and reliability. Suggestions and our review limitations are
also discussed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exponentially Faster Language Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peter Belcak, Roger Wattenhofer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models only really need to use an exponential fraction of their
neurons for individual inferences. As proof, we present UltraFastBERT, a BERT
variant that uses 0.3% of its neurons during inference while performing on par
with similar BERT models. UltraFastBERT selectively engages just 12 out of 4095
neurons for each layer inference. This is achieved by replacing feedforward
networks with fast feedforward networks (FFFs). While no truly efficient
implementation currently exists to unlock the full acceleration potential of
conditional neural execution, we provide high-level CPU code achieving 78x
speedup over the optimized baseline feedforward implementation, and a PyTorch
implementation delivering 40x speedup over the equivalent batched feedforward
inference. We publish our training code, benchmarking setup, and model weights.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Streaming Language Models with Attention Sinks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.17453v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.17453v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, Mike Lewis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deploying Large Language Models (LLMs) in streaming applications such as
multi-round dialogue, where long interactions are expected, is urgently needed
but poses two major challenges. Firstly, during the decoding stage, caching
previous tokens' Key and Value states (KV) consumes extensive memory. Secondly,
popular LLMs cannot generalize to longer texts than the training sequence
length. Window attention, where only the most recent KVs are cached, is a
natural approach -- but we show that it fails when the text length surpasses
the cache size. We observe an interesting phenomenon, namely attention sink,
that keeping the KV of initial tokens will largely recover the performance of
window attention. In this paper, we first demonstrate that the emergence of
attention sink is due to the strong attention scores towards initial tokens as
a ``sink'' even if they are not semantically important. Based on the above
analysis, we introduce StreamingLLM, an efficient framework that enables LLMs
trained with a finite length attention window to generalize to infinite
sequence lengths without any fine-tuning. We show that StreamingLLM can enable
Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language
modeling with up to 4 million tokens and more. In addition, we discover that
adding a placeholder token as a dedicated attention sink during pre-training
can further improve streaming deployment. In streaming settings, StreamingLLM
outperforms the sliding window recomputation baseline by up to 22.2x speedup.
Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Short Text Matching Model Enhanced with Knowledge via Contrastive
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.03898v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.03898v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiqiang Liu, Mengmeng Cui, Hanjie Mai, Qiang Zhang, Shaohua Xu, Xiangzheng Liu, Yanlong Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, short Text Matching tasks have been widely applied in the
fields ofadvertising search and recommendation. The difficulty lies in the lack
of semantic information and word ambiguity caused by the short length of the
text. Previous works have introduced complement sentences or knowledge bases to
provide additional feature information. However, these methods have not fully
interacted between the original sentence and the complement sentence, and have
not considered the noise issue that may arise from the introduction of external
knowledge bases. Therefore, this paper proposes a short Text Matching model
that combines contrastive learning and external knowledge. The model uses a
generative model to generate corresponding complement sentences and uses the
contrastive learning method to guide the model to obtain more semantically
meaningful encoding of the original sentence. In addition, to avoid noise, we
use keywords as the main semantics of the original sentence to retrieve
corresponding knowledge words in the knowledge base, and construct a knowledge
graph. The graph encoding model is used to integrate the knowledge base
information into the model. Our designed model achieves state-of-the-art
performance on two publicly available Chinese Text Matching datasets,
demonstrating the effectiveness of our model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages,2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extraction and Summarization of Explicit Video Content using Multi-Modal
  Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10899v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10899v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaunak Joshi, Raghav Gaggar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increase in video-sharing platforms across the internet, it is
difficult for humans to moderate the data for explicit content. Hence, an
automated pipeline to scan through video data for explicit content has become
the need of the hour. We propose a novel pipeline that uses multi-modal deep
learning to first extract the explicit segments of input videos and then
summarize their content using text to determine its age appropriateness and age
rating. We also evaluate our pipeline's effectiveness in the end using standard
metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DoReMi: Optimizing Data Mixtures Speeds Up Language Model <span class="highlight-title">Pretrain</span>ing <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.10429v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.10429v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V. Le, Tengyu Ma, Adams Wei Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The mixture proportions of pretraining data domains (e.g., Wikipedia, books,
web text) greatly affect language model (LM) performance. In this paper, we
propose Domain Reweighting with Minimax Optimization (DoReMi), which first
trains a small proxy model using group distributionally robust optimization
(Group DRO) over domains to produce domain weights (mixture proportions)
without knowledge of downstream tasks. We then resample a dataset with these
domain weights and train a larger, full-sized model. In our experiments, we use
DoReMi on a 280M-parameter proxy model to set the domain weights for training
an 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi
improves perplexity across all domains, even when it downweights a domain.
DoReMi improves average few-shot downstream accuracy by 6.5% points over a
baseline model trained using The Pile's default domain weights and reaches the
baseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi,
which has no knowledge of downstream tasks, even matches the performance of
using domain weights tuned on downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2023</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2023-11-20T00:00:00Z">2023-11-20</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unifying Corroborative and Contributive Attributions in Large Language
  Models <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12233v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12233v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Theodora Worledge, Judy Hanwen Shen, Nicole Meister, Caleb Winston, Carlos Guestrin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As businesses, products, and services spring up around large language models,
the trustworthiness of these models hinges on the verifiability of their
outputs. However, methods for explaining language model outputs largely fall
across two distinct fields of study which both use the term "attribution" to
refer to entirely separate techniques: citation generation and training data
attribution. In many modern applications, such as legal document generation and
medical question answering, both types of attributions are important. In this
work, we argue for and present a unified framework of large language model
attributions. We show how existing methods of different types of attribution
fall under the unified framework. We also use the framework to discuss
real-world use cases where one or both types of attributions are required. We
believe that this unified framework will guide the use case driven development
of systems that leverage both types of attribution, as well as the
standardization of their evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS ATTRIB Workshop 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Closed-Access Multilingual Embedding for Automatic Sentence
  Alignment in Low Resource Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12179v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12179v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Idris Abdulmumin, Auwal Abubakar Khalid, Shamsuddeen Hassan Muhammad, Ibrahim Said Ahmad, Lukman Jibril Aliyu, Babangida Sani, Bala Mairiga Abduljalil, Sani Ahmad Hassan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The importance of qualitative parallel data in machine translation has long
been determined but it has always been very difficult to obtain such in
sufficient quantity for the majority of world languages, mainly because of the
associated cost and also the lack of accessibility to these languages. Despite
the potential for obtaining parallel datasets from online articles using
automatic approaches, forensic investigations have found a lot of
quality-related issues such as misalignment, and wrong language codes. In this
work, we present a simple but qualitative parallel sentence aligner that
carefully leveraged the closed-access Cohere multilingual embedding, a solution
that ranked second in the just concluded #CoHereAIHack 2023 Challenge (see
https://ai6lagos.devpost.com). The proposed approach achieved $94.96$ and
$54.83$ f1 scores on FLORES and MAFAND-MT, compared to $3.64$ and $0.64$ of
LASER respectively. Our method also achieved an improvement of more than 5 BLEU
scores over LASER, when the resulting datasets were used with MAFAND-MT dataset
to train translation models. Our code and data are available for research
purposes here (https://github.com/abumafrim/Cohere-Align).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in the proceedings of ICCAIT 2023. 6 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human Learning by Model Feedback: The Dynamics of Iterative <span class="highlight-title">Prompt</span>ing
  with Midjourney <span class="chip">EMNLP23</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12131v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12131v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shachar Don-Yehiya, Leshem Choshen, Omri Abend
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating images with a Text-to-Image model often requires multiple trials,
where human users iteratively update their prompt based on feedback, namely the
output image. Taking inspiration from cognitive work on reference games and
dialogue alignment, this paper analyzes the dynamics of the user prompts along
such iterations. We compile a dataset of iterative interactions of human users
with Midjourney. Our analysis then reveals that prompts predictably converge
toward specific traits along these iterations. We further study whether this
convergence is due to human users, realizing they missed important details, or
due to adaptation to the model's ``preferences'', producing better images for a
specific language style. We show initial evidence that both possibilities are
at play. The possibility that users adapt to the model's preference raises
concerns about reusing user data for further training. The prompts may be
biased towards the preferences of a specific model, rather than align with
human intentions and natural manner of expression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP23</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient
  Language Model Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12023v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12023v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Guo, Philip Greengard, Eric P. Xing, Yoon Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a simple approach for memory-efficient adaptation of pretrained
language models. Our approach uses an iterative algorithm to decompose each
pretrained matrix into a high-precision low-rank component and a
memory-efficient quantized component. During finetuning, the quantized
component remains fixed and only the low-rank component is updated. We present
an integer linear programming formulation of the quantization component which
enables dynamic configuration of quantization parameters (e.g., bit-width,
block size) for each matrix given an overall target memory budget. We further
explore a data-aware version of the algorithm which uses an approximation of
the Fisher information matrix to weight the reconstruction objective during
matrix decomposition. Experiments on adapting RoBERTa and LLaMA-2 (7B and 70B)
demonstrate that our low-rank plus quantized matrix decomposition approach
(LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and moreover enables
more aggressive quantization. For example, on the OpenAssistant benchmark
LQ-LoRA is able to learn a 2.5-bit LLaMA-2 model that is competitive with a
model finetuned with 4-bit QLoRA. When finetuned on a language modeling
calibration dataset, LQ-LoRA can also be used for model compression; in this
setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when
including the low-rank components and requires 27GB of GPU memory) is
competitive with the original model in full precision.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GPQA: A Graduate-Level Google-Proof Q&A Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present GPQA, a challenging dataset of 448 multiple-choice questions
written by domain experts in biology, physics, and chemistry. We ensure that
the questions are high-quality and extremely difficult: experts who have or are
pursuing PhDs in the corresponding domains reach 65% accuracy (74% when
discounting clear mistakes the experts identified in retrospect), while highly
skilled non-expert validators only reach 34% accuracy, despite spending on
average over 30 minutes with unrestricted access to the web (i.e., the
questions are "Google-proof"). The questions are also difficult for
state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving
39% accuracy. If we are to use future AI systems to help us answer very hard
questions, for example, when developing new scientific knowledge, we need to
develop scalable oversight methods that enable humans to supervise their
outputs, which may be difficult even if the supervisors are themselves skilled
and knowledgeable. The difficulty of GPQA both for skilled non-experts and
frontier AI systems should enable realistic scalable oversight experiments,
which we hope can help devise ways for human experts to reliably get truthful
information from AI systems that surpass human capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 5 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">GPT</span>-4V(ision) for Robotics: Multimodal Task Planning from Human
  Demonstration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.12015v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.12015v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a pipeline that enhances a general-purpose Vision Language
Model, GPT-4V(ision), by integrating observations of human actions to
facilitate robotic manipulation. This system analyzes videos of humans
performing tasks and creates executable robot programs that incorporate
affordance insights. The computation starts by analyzing the videos with GPT-4V
to convert environmental and action details into text, followed by a
GPT-4-empowered task planner. In the following analyses, vision systems
reanalyze the video with the task plan. Object names are grounded using an
open-vocabulary object detector, while focus on the hand-object relation helps
to detect the moment of grasping and releasing. This spatiotemporal grounding
allows the vision systems to further gather affordance data (e.g., grasp type,
way points, and body postures). Experiments across various scenarios
demonstrate this method's efficacy in achieving real robots' operations from
human demonstrations in a zero-shot manner. The prompts of GPT-4V/GPT-4 are
available at this project page:
https://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 10 figures, 1 table. Last updated on November 20th, 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ H-COAL: Human Correction of AI-Generated Labels for Biomedical Named
  <span class="highlight-title">Entity</span> Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11981v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11981v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaojing Duan, John P. Lalor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of machine learning models for NLP tasks,
collecting high-fidelity labels from AI models is a realistic possibility.
Firms now make AI available to customers via predictions as a service (PaaS).
This includes PaaS products for healthcare. It is unclear whether these labels
can be used for training a local model without expensive annotation checking by
in-house experts. In this work, we propose a new framework for Human Correction
of AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can
selectively correct labels and approach gold standard performance (100% human
labeling) with significantly less human effort. We show that correcting 5% of
labels can close the AI-human performance gap by up to 64% relative
improvement, and correcting 20% of labels can close the performance gap by up
to 86% relative improvement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at Conference on Information Systems and Technology (CIST)
  2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Potential and Limitations of Few-Shot In-Context Learning to
  Generate Metamorphic Specifications for Tax Preparation Software <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11979v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11979v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dananjay Srinivas, Rohan Das, Saeid Tizpaz-Niari, Ashutosh Trivedi, Maria Leonor Pacheco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the ever-increasing complexity of income tax laws in the United
States, the number of US taxpayers filing their taxes using tax preparation
software (henceforth, tax software) continues to increase. According to the
U.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed
their individual income taxes using tax software. Given the legal consequences
of incorrectly filing taxes for the taxpayer, ensuring the correctness of tax
software is of paramount importance. Metamorphic testing has emerged as a
leading solution to test and debug legal-critical tax software due to the
absence of correctness requirements and trustworthy datasets. The key idea
behind metamorphic testing is to express the properties of a system in terms of
the relationship between one input and its slightly metamorphosed twinned
input. Extracting metamorphic properties from IRS tax publications is a tedious
and time-consuming process. As a response, this paper formulates the task of
generating metamorphic specifications as a translation task between properties
extracted from tax documents - expressed in natural language - to a contrastive
first-order logic form. We perform a systematic analysis on the potential and
limitations of in-context learning with Large Language Models(LLMs) for this
task, and outline a research agenda towards automating the generation of
metamorphic specifications for tax preparation software.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Proceedings of the Natural Legal Language Processing
  Workshop, EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context-aware Neural Machine Translation for English-Japanese Business
  Scene Dialogues 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11976v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11976v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sumire Honda, Patrick Fernandes, Chrysoula Zerva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable advancements in machine translation, the current
sentence-level paradigm faces challenges when dealing with highly-contextual
languages like Japanese. In this paper, we explore how context-awareness can
improve the performance of the current Neural Machine Translation (NMT) models
for English-Japanese business dialogues translation, and what kind of context
provides meaningful information to improve translation. As business dialogue
involves complex discourse phenomena but offers scarce training resources, we
adapted a pretrained mBART model, finetuning on multi-sentence dialogue data,
which allows us to experiment with different contexts. We investigate the
impact of larger context sizes and propose novel context tokens encoding
extra-sentential information, such as speaker turn and scene type. We make use
of Conditional Cross-Mutual Information (CXMI) to explore how much of the
context the model uses and generalise CXMI to study the impact of the
extra-sentential context. Overall, we find that models leverage both preceding
sentences and extra-sentential context (with CXMI increasing with context size)
and we provide a more focused analysis on honorifics translation. Regarding
translation quality, increased source-side context paired with scene and
speaker information improves the model performance compared to previous work
and our context-agnostic baselines, measured in BLEU and COMET metrics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MT Summit 2023, research track, link to paper in proceedings:
  https://aclanthology.org/2023.mtsummit-research.23/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Training Distributions with Scalable Online Bilevel
  Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11973v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11973v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Grangier, Pierre Ablin, Awni Hannun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large neural networks pretrained on web-scale corpora are central to modern
machine learning. In this paradigm, the distribution of the large,
heterogeneous pretraining data rarely matches that of the application domain.
This work considers modifying the pretraining distribution in the case where
one has a small sample of data reflecting the targeted test conditions. We
propose an algorithm motivated by a recent formulation of this setting as an
online, bilevel optimization problem. With scalability in mind, our algorithm
prioritizes computing gradients at training points which are likely to most
improve the loss on the targeted distribution. Empirically, we show that in
some cases this approach is beneficial over existing strategies from the domain
adaptation literature but may not succeed in other cases. We propose a simple
test to evaluate when our approach can be expected to work well and point
towards further research to address current limitations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic Analysis of Substantiation in Scientific Peer <span class="highlight-title">Review</span>s <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11967v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11967v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanzhu Guo, Guokan Shang, Virgile Rennard, Michalis Vazirgiannis, Chloé Clavel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing amount of problematic peer reviews in top AI conferences,
the community is urgently in need of automatic quality control measures. In
this paper, we restrict our attention to substantiation -- one popular quality
aspect indicating whether the claims in a review are sufficiently supported by
evidence -- and provide a solution automatizing this evaluation process. To
achieve this goal, we first formulate the problem as claim-evidence pair
extraction in scientific peer reviews, and collect SubstanReview, the first
annotated dataset for this task. SubstanReview consists of 550 reviews from NLP
conferences annotated by domain experts. On the basis of this dataset, we train
an argument mining system to automatically analyze the level of substantiation
in peer reviews. We also perform data analysis on the SubstanReview dataset to
obtain meaningful insights on peer reviewing quality in NLP conferences over
recent years.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FinanceBench: A New Benchmark for Financial Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11944v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11944v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, Bertie Vidgen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  FinanceBench is a first-of-its-kind test suite for evaluating the performance
of LLMs on open book financial question answering (QA). It comprises 10,231
questions about publicly traded companies, with corresponding answers and
evidence strings. The questions in FinanceBench are ecologically valid and
cover a diverse set of scenarios. They are intended to be clear-cut and
straightforward to answer to serve as a minimum performance standard. We test
16 state of the art model configurations (including GPT-4-Turbo, Llama2 and
Claude2, with vector stores and long context prompts) on a sample of 150 cases
from FinanceBench, and manually review their answers (n=2,400). The cases are
available open-source. We show that existing LLMs have clear limitations for
financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly
answered or refused to answer 81% of questions. While augmentation techniques
such as using longer context window to feed in relevant evidence improve
performance, they are unrealistic for enterprise settings due to increased
latency and cannot support larger financial documents. We find that all models
examined exhibit weaknesses, such as hallucinations, that limit their
suitability for use by enterprises.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Dataset is available at:
  https://huggingface.co/datasets/PatronusAI/financebench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs as Visual Explainers: Advancing Image Classification with Evolving
  Visual Descriptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songhao Han, Le Zhuo, Yue Liao, Si Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-language models (VLMs) offer a promising paradigm for image
classification by comparing the similarity between images and class embeddings.
A critical challenge lies in crafting precise textual representations for class
names. While previous studies have leveraged recent advancements in large
language models (LLMs) to enhance these descriptors, their outputs often suffer
from ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent
reliance on textual interactions with LLMs, leading to a mismatch between the
generated text and the visual content in VLMs' latent space - a phenomenon we
term the "explain without seeing" dilemma. 2) The oversight of the inter-class
relationships, resulting in descriptors that fail to differentiate similar
classes effectively. To address these issues, we propose a novel image
classification framework combining VLMs with LLMs, named Iterative Optimization
with Visual Feedback. In particular, our method develops an LLM-based agent,
employing an evolutionary optimization strategy to refine class descriptors.
Crucially, we incorporate visual feedback from VLM classification metrics,
thereby guiding the optimization process with concrete visual data. Our method
leads to improving accuracy on a wide range of image classification benchmarks,
with 3.47\% average gains over state-of-the-art methods. We also highlight the
resulting descriptions serve as explainable and robust features that can
consistently improve the performance across various backbone models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Valid and Natural Adversarial Examples with Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11861v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11861v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning-based natural language processing (NLP) models, particularly
pre-trained language models (PLMs), have been revealed to be vulnerable to
adversarial attacks. However, the adversarial examples generated by many
mainstream word-level adversarial attack models are neither valid nor natural,
leading to the loss of semantic maintenance, grammaticality, and human
imperceptibility. Based on the exceptional capacity of language understanding
and generation of large language models (LLMs), we propose LLM-Attack, which
aims at generating both valid and natural adversarial examples with LLMs. The
method consists of two stages: word importance ranking (which searches for the
most vulnerable words) and word synonym replacement (which substitutes them
with their synonyms obtained from LLMs). Experimental results on the Movie
Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline
adversarial attack models illustrate the effectiveness of LLM-Attack, and it
outperforms the baselines in human and GPT-4 evaluation by a significant
margin. The model can generate adversarial examples that are typically valid
and natural, with the preservation of semantic meaning, grammaticality, and
human imperceptibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evil Geniuses: Delving into the Safety of LLM-based Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11855v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11855v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Tian, Xiao Yang, Jingyuan Zhang, Yinpeng Dong, Hang Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in large language models (LLMs) have led to a
resurgence in LLM-based agents, which demonstrate impressive human-like
behaviors and cooperative capabilities in various interactions and strategy
formulations. However, evaluating the safety of LLM-based agents remains a
complex challenge. This paper elaborately conducts a series of manual jailbreak
prompts along with a virtual chat-powered evil plan development team, dubbed
Evil Geniuses, to thoroughly probe the safety aspects of these agents. Our
investigation reveals three notable phenomena: 1) LLM-based agents exhibit
reduced robustness against malicious attacks. 2) the attacked agents could
provide more nuanced responses. 3) the detection of the produced improper
responses is more challenging. These insights prompt us to question the
effectiveness of LLM-based attacks on agents, highlighting vulnerabilities at
various levels and within different role specializations within the
system/agent of LLM-based agents. Extensive evaluation and discussion reveal
that LLM-based agents face significant challenges in safety and yield insights
for future research. Our code is available at
https://github.com/T1aNS1R/Evil-Geniuses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for
  Parsing Multinational Street Addresses <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11846v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11846v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Beauchemin, Marouane Yassine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Segmenting an address into meaningful components, also known as address
parsing, is an essential step in many applications from record linkage to
geocoding and package delivery. Consequently, a lot of work has been dedicated
to develop accurate address parsing techniques, with machine learning and
neural network methods leading the state-of-the-art scoreboard. However, most
of the work on address parsing has been confined to academic endeavours with
little availability of free and easy-to-use open-source solutions.
  This paper presents Deepparse, a Python open-source, extendable, fine-tunable
address parsing solution under LGPL-3.0 licence to parse multinational
addresses using state-of-the-art deep learning algorithms and evaluated on over
60 countries. It can parse addresses written in any language and use any
address standard. The pre-trained model achieves average $99~\%$ parsing
accuracies on the countries used for training with no pre-processing nor
post-processing needed. Moreover, the library supports fine-tuning with new
data to generate a custom address parser.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP 2024 NLP-OSS workshop. arXiv admin note: text
  overlap with arXiv:2006.16152, arXiv:2112.04008</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How to Use Large Language Models for Text Coding: The Case of Fatherhood
  Roles in Public Policy Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11844v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11844v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lorenzo Lupo, Oscar Magnusson, Dirk Hovy, Elin Naurin, Lena Wängnerud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) like GPT-3 and GPT-4 have
opened up new opportunities for text analysis in political science. They
promise automation with better results and less programming. In this study, we
evaluate LLMs on three original coding tasks of non-English political science
texts, and we provide a detailed description of a general workflow for using
LLMs for text coding in political science research. Our use case offers a
practical guide for researchers looking to incorporate LLMs into their research
on text analysis. We find that, when provided with detailed label definitions
and coding examples, an LLM can be as good as or even better than a human
annotator while being much faster (up to hundreds of times), considerably
cheaper (costing up to 60% less than human coding), and much easier to scale to
large amounts of text. Overall, LLMs present a viable option for most text
coding projects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ System 2 Attention (is something you might need too) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11829v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11829v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jason Weston, Sainbayar Sukhbaatar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soft attention in Transformer-based Large Language Models (LLMs) is
susceptible to incorporating irrelevant information from the context into its
latent representations, which adversely affects next token generations. To help
rectify these issues, we introduce System 2 Attention (S2A), which leverages
the ability of LLMs to reason in natural language and follow instructions in
order to decide what to attend to. S2A regenerates the input context to only
include the relevant portions, before attending to the regenerated context to
elicit the final response. In experiments, S2A outperforms standard
attention-based LLMs on three tasks containing opinion or irrelevant
information, QA, math word problems and longform generation, where S2A
increases factuality and objectivity, and decreases sycophancy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Grammatical Error Correction Via Multi-Task Training and
  Optimized Training Schedule <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11813v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11813v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrey Bout, Alexander Podolskiy, Sergey Nikolenko, Irina Piontkovskaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Progress in neural grammatical error correction (GEC) is hindered by the lack
of annotated training data. Sufficient amounts of high-quality manually
annotated data are not available, so recent research has relied on generating
synthetic data, pretraining on it, and then fine-tuning on real datasets;
performance gains have been achieved either by ensembling or by using huge
pretrained models such as XXL-T5 as the backbone. In this work, we explore an
orthogonal direction: how to use available data more efficiently. First, we
propose auxiliary tasks that exploit the alignment between the original and
corrected sentences, such as predicting a sequence of corrections. We formulate
each task as a sequence-to-sequence problem and perform multi-task training.
Second, we discover that the order of datasets used for training and even
individual instances within a dataset may have important effects on the final
performance, so we set out to find the best training schedule. Together, these
two ideas lead to significant improvements, producing results that improve
state of the art with much smaller models; in particular, we outperform the
best models based on T5-XXL (11B parameters) with a BART-based model (400M
parameters).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Igniting Language Intelligence: The Hitchhiker's Guide From
  Chain-of-Thought Reasoning to Language Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11797v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11797v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, Hai Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have dramatically enhanced the field of language
intelligence, as demonstrably evidenced by their formidable empirical
performance across a spectrum of complex reasoning tasks. Additionally,
theoretical proofs have illuminated their emergent reasoning capabilities,
providing a compelling showcase of their advanced cognitive abilities in
linguistic contexts. Critical to their remarkable efficacy in handling complex
reasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning
techniques, obliging them to formulate intermediate steps en route to deriving
an answer. The CoT reasoning approach has not only exhibited proficiency in
amplifying reasoning performance but also in enhancing interpretability,
controllability, and flexibility. In light of these merits, recent research
endeavors have extended CoT reasoning methodologies to nurture the development
of autonomous language agents, which adeptly adhere to language instructions
and execute actions within varied environments. This survey paper orchestrates
a thorough discourse, penetrating vital research dimensions, encompassing: (i)
the foundational mechanics of CoT techniques, with a focus on elucidating the
circumstances and justification behind its efficacy; (ii) the paradigm shift in
CoT; and (iii) the burgeoning of language agents fortified by CoT approaches.
Prospective research avenues envelop explorations into generalization,
efficiency, customization, scaling, and safety. This paper caters to a wide
audience, including beginners seeking comprehensive knowledge of CoT reasoning
and language agents, as well as experienced researchers interested in
foundational mechanics and engaging in cutting-edge discussions on these
topics. A repository for the related papers is available at
https://github.com/Zoeyyao27/CoT-Igniting-Agent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Boundaries: A Comprehensive <span class="highlight-title">Survey</span> of Transferable Attacks on AI
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial Intelligence (AI) systems such as autonomous vehicles, facial
recognition, and speech recognition systems are increasingly integrated into
our daily lives. However, despite their utility, these AI systems are
vulnerable to a wide range of attacks such as adversarial, backdoor, data
poisoning, membership inference, model inversion, and model stealing attacks.
In particular, numerous attacks are designed to target a particular model or
system, yet their effects can spread to additional targets, referred to as
transferable attacks. Although considerable efforts have been directed toward
developing transferable attacks, a holistic understanding of the advancements
in transferable attacks remains elusive. In this paper, we comprehensively
explore learning-based attacks from the perspective of transferability,
particularly within the context of cyber-physical security. We delve into
different domains -- the image, text, graph, audio, and video domains -- to
highlight the ubiquitous and pervasive nature of transferable attacks. This
paper categorizes and reviews the architecture of existing attacks from various
viewpoints: data, process, model, and system. We further examine the
implications of transferable attacks in practical scenarios such as autonomous
driving, speech recognition, and large language models (LLMs). Additionally, we
outline the potential research directions to encourage efforts in exploring the
landscape of transferable attacks. This survey offers a holistic understanding
of the prevailing transferable attacks and their impacts across different
domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11745v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11745v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jungil Kong, Junmo Lee, Jeongmin Kim, Beomjeong Kim, Jihoon Park, Dohee Kong, Changheon Lee, Sangjin Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose a novel method for modeling numerous speakers, which
enables expressing the overall characteristics of speakers in detail like a
trained multi-speaker model without additional training on the target speaker's
dataset. Although various works with similar purposes have been actively
studied, their performance has not yet reached that of trained multi-speaker
models due to their fundamental limitations. To overcome previous limitations,
we propose effective methods for feature learning and representing target
speakers' speech characteristics by discretizing the features and conditioning
them to a speech synthesis model. Our method obtained a significantly higher
similarity mean opinion score (SMOS) in subjective similarity evaluation than
seen speakers of a best-performing multi-speaker model, even with unseen
speakers. The proposed method also outperforms a zero-shot method by
significant margins. Furthermore, our method shows remarkable performance in
generating new artificial speakers. In addition, we demonstrate that the
encoded latent features are sufficiently informative to reconstruct an original
speaker's speech completely. It implies that our method can be used as a
general methodology to encode and reconstruct speakers' characteristics in
various tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Control in Hybrid Chatbots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Rüdel, Jochen L. Leidner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Customer data typically is held in database systems, which can be seen as
rule-based knowledge base, whereas businesses increasingly want to benefit from
the capabilities of large, pre-trained language models.
  In this technical report, we describe a case study of how a commercial rule
engine and an integrated neural chatbot may be integrated, and what level of
control that particular integration mode leads to. We also discuss alternative
ways (including past ways realized in other systems) how researchers strive to
maintain control and avoid what has recently been called model "hallucination".
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse Low-rank Adaptation of <span class="highlight-title">Pre-train</span>ed Language Models <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning pre-trained large language models in a parameter-efficient manner
is widely studied for its effectiveness and efficiency. The popular method of
low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the
adaptation process is intrinsically low-dimensional. Although LoRA has
demonstrated commendable performance, it is implemented with a fixed and
unalterable intrinsic rank that might not always be the ideal choice.
Recognizing the need for more flexible adaptation, we extend the methodology of
LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that
enables dynamic adjustments to the intrinsic rank during the adaptation
process. We achieve this through the incorporation of a gate unit optimized
with proximal gradient method in the training stage, controlling the
cardinality of rank under the sparsity of the gate. In the subsequent inference
stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks,
to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our
approach strengthens the representation power of LoRA by initializing it with a
higher rank, while efficiently taming a temporarily increased number of
parameters via updating in a sparse way. We further introduce a sparsifying
scheduler for SoRA, aiming to examine the impact of the number of non-zero
parameters on the model's memorization and generalization. Our experimental
results demonstrate that SoRA can outperform other baselines even with 70%
retained parameters and 70% training time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2023 (Main Conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Refactoring Programs Using Large Language Models with Few-Shot Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atsushi Shirafuji, Yusuke Oda, Jun Suzuki, Makoto Morishita, Yutaka Watanobe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A less complex and more straightforward program is a crucial factor that
enhances its maintainability and makes writing secure and bug-free programs
easier. However, due to its heavy workload and the risks of breaking the
working programs, programmers are reluctant to do code refactoring, and thus,
it also causes the loss of potential learning experiences. To mitigate this, we
demonstrate the application of using a large language model (LLM), GPT-3.5, to
suggest less complex versions of the user-written Python program, aiming to
encourage users to learn how to write better programs. We propose a method to
leverage the prompting with few-shot examples of the LLM by selecting the
best-suited code refactoring examples for each target programming problem based
on the prior evaluation of prompting with the one-shot example. The
quantitative evaluation shows that 95.68% of programs can be refactored by
generating 10 candidates each, resulting in a 17.35% reduction in the average
cyclomatic complexity and a 25.84% decrease in the average number of lines
after filtering only generated programs that are semantically correct.
Furthermore, the qualitative evaluation shows outstanding capability in code
formatting, while unnecessary behaviors such as deleting or translating
comments are also observed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 10 figures, accepted to the 30th Asia-Pacific Software
  Engineering Conference (APSEC 2023)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse
  Biomedical Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11608v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11608v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ling Luo, Jinzhong Ning, Yingwen Zhao, Zhijun Wang, Zeyuan Ding, Peng Chen, Weiru Fu, Qinyu Han, Guangtao Xu, Yunzhi Qiu, Dinghao Pan, Jiru Li, Hao Li, Wenduo Feng, Senbo Tu, Yuqi Liu, Zhihao Yang, Jian Wang, Yuanyuan Sun, Hongfei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have shown promising
results across a variety of natural language processing (NLP) tasks. The
application of LLMs to specific domains, such as biomedicine, has achieved
increased attention. However, most biomedical LLMs focus on enhancing
performance in monolingual biomedical question answering and conversation
tasks. To further investigate the effectiveness of the LLMs on diverse
biomedical NLP tasks in different languages, we present Taiyi, a bilingual
(English and Chinese) fine-tuned LLM for diverse biomedical tasks. In this
work, we first curated a comprehensive collection of 140 existing biomedical
text mining datasets across over 10 task types. Subsequently, a two-stage
strategy is proposed for supervised fine-tuning to optimize the model
performance across varied tasks. Experimental results on 13 test sets covering
named entity recognition, relation extraction, text classification, question
answering tasks demonstrate Taiyi achieves superior performance compared to
general LLMs. The case study involving additional biomedical NLP tasks further
shows Taiyi's considerable potential for bilingual biomedical multi-tasking.
The source code, datasets, and model for Taiyi are freely available at
https://github.com/DUTIR-BioNLP/Taiyi-LLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Addressing the Length Bias Problem in Document-Level Neural Machine
  Translation <span class="chip">EMNLP2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuocheng Zhang, Shuhao Gu, Min Zhang, Yang Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document-level neural machine translation (DNMT) has shown promising results
by incorporating more context information. However, this approach also
introduces a length bias problem, whereby DNMT suffers from significant
translation quality degradation when decoding documents that are much shorter
or longer than the maximum sequence length during training. %i.e., the length
bias problem. To solve the length bias problem, we propose to improve the DNMT
model in training method, attention mechanism, and decoding strategy. Firstly,
we propose to sample the training data dynamically to ensure a more uniform
distribution across different sequence lengths. Then, we introduce a
length-normalized attention mechanism to aid the model in focusing on target
information, mitigating the issue of attention divergence when processing
longer sequences. Lastly, we propose a sliding window strategy during decoding
that integrates as much context information as possible without exceeding the
maximum sequence length. The experimental results indicate that our method can
bring significant improvements on several open datasets, and further analysis
shows that our method can significantly alleviate the length bias problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Filling the Image Information Gap for VQA: <span class="highlight-title">Prompt</span>ing Large Language
  Models to Proactively Ask Questions <span class="chip">EMNLP2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyue Wang, Chi Chen, Peng Li, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) demonstrate impressive reasoning ability and the
maintenance of world knowledge not only in natural language tasks, but also in
some vision-language tasks such as open-domain knowledge-based visual question
answering (OK-VQA). As images are invisible to LLMs, researchers convert images
to text to engage LLMs into the visual question reasoning procedure. This leads
to discrepancies between images and their textual representations presented to
LLMs, which consequently impedes final reasoning performance. To fill the
information gap and better leverage the reasoning capability, we design a
framework that enables LLMs to proactively ask relevant questions to unveil
more details in the image, along with filters for refining the generated
information. We validate our idea on OK-VQA and A-OKVQA. Our method
continuously boosts the performance of baselines methods by an average gain of
2.15% on OK-VQA, and achieves consistent improvements across different LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How well Chat<span class="highlight-title">GPT</span> understand Malaysian English? An Evaluation on Named
  <span class="highlight-title">Entity</span> Recognition and <span class="highlight-title">Relation</span> Extraction <span class="chip">EMNLP
  2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Raj Chanthran, Lay-Ki Soon, Huey Fang Ong, Bhawani Selvaretnam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, ChatGPT has attracted a lot of interest from both researchers and
the general public. While the performance of ChatGPT in named entity
recognition and relation extraction from Standard English texts is
satisfactory, it remains to be seen if it can perform similarly for Malaysian
English. Malaysian English is unique as it exhibits morphosyntactic and
semantical adaptation from local contexts. In this study, we assess ChatGPT's
capability in extracting entities and relations from the Malaysian English News
(MEN) dataset. We propose a three-step methodology referred to as
\textbf{\textit{educate-predict-evaluate}}. The performance of ChatGPT is
assessed using F1-Score across 18 unique prompt settings, which were carefully
engineered for a comprehensive review. From our evaluation, we found that
ChatGPT does not perform well in extracting entities from Malaysian English
news articles, with the highest F1-Score of 0.497. Further analysis shows that
the morphosyntactic adaptation in Malaysian English caused the limitation.
However, interestingly, this morphosyntactic adaptation does not impact the
performance of ChatGPT for relation extraction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Generation, Evaluation & Metrics (GEM) Workshop at EMNLP
  2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KBioXLM: A Knowledge-anchored Biomedical Multilingual <span class="highlight-title">Pretrain</span>ed
  Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11564v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11564v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Geng, Xu Yan, Ziqiang Cao, Juntao Li, Wenjie Li, Sujian Li, Xinjie Zhou, Yang Yang, Jun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most biomedical pretrained language models are monolingual and cannot handle
the growing cross-lingual requirements. The scarcity of non-English domain
corpora, not to mention parallel data, poses a significant hurdle in training
multilingual biomedical models. Since knowledge forms the core of
domain-specific corpora and can be translated into various languages
accurately, we propose a model called KBioXLM, which transforms the
multilingual pretrained model XLM-R into the biomedical domain using a
knowledge-anchored approach. We achieve a biomedical multilingual corpus by
incorporating three granularity knowledge alignments (entity, fact, and passage
levels) into monolingual corpora. Then we design three corresponding training
tasks (entity masking, relation masking, and passage relation prediction) and
continue training on top of the XLM-R model to enhance its domain cross-lingual
ability. To validate the effectiveness of our model, we translate the English
benchmarks of multiple tasks into Chinese. Experimental results demonstrate
that our model significantly outperforms monolingual and multilingual
pretrained models in cross-lingual zero-shot and few-shot scenarios, achieving
improvements of up to 10+ points. Our code is publicly available at
https://github.com/ngwlh-gl/KBioXLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring <span class="highlight-title">Prompt</span>ing Large Language Models as Explainable Metrics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11552v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11552v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ghazaleh Mahmoudi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes the IUST NLP Lab submission to the Prompting Large
Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023
Workshop on Evaluation & Comparison of NLP Systems. We have proposed a
zero-shot prompt-based strategy for explainable evaluation of the summarization
task using Large Language Models (LLMs). The conducted experiments demonstrate
the promising potential of LLMs as evaluation metrics in Natural Language
Processing (NLP), particularly in the field of summarization. Both few-shot and
zero-shot approaches are employed in these experiments. The performance of our
best provided prompts achieved a Kendall correlation of 0.477 with human
evaluations in the text summarization task on the test data. Code and results
are publicly available on GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, Eval4NLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context
  Learning <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11551v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11551v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Quanyu Long, Wenya Wang, Sinno Jialin Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have showcased their capability with few-shot
inference known as in-context learning. However, in-domain demonstrations are
not always readily available in real scenarios, leading to cross-domain
in-context learning. Besides, LLMs are still facing challenges in long-tail
knowledge in unseen and unfamiliar domains. The above limitations demonstrate
the necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study
the UDA problem under an in-context learning setting to adapt language models
from the source domain to the target domain without any target labels. The core
idea is to retrieve a subset of cross-domain elements that are the most similar
to the query, and elicit language model to adapt in an in-context manner by
learning both target domain distribution and the discriminative task signal
simultaneously with the augmented cross-domain in-context examples. We devise
different prompting and training strategies, accounting for different LM
architectures to learn the target distribution via language modeling. With
extensive experiments on Sentiment Analysis (SA) and Named Entity Recognition
(NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer
and demonstrate significant improvements over baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-teacher Distillation for Multilingual Spelling Correction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11518v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11518v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingfen Zhang, Xuan Guo, Sravan Bodapati, Christopher Potts
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate spelling correction is a critical step in modern search interfaces,
especially in an era of mobile devices and speech-to-text interfaces. For
services that are deployed around the world, this poses a significant challenge
for multilingual NLP: spelling errors need to be caught and corrected in all
languages, and even in queries that use multiple languages. In this paper, we
tackle this challenge using multi-teacher distillation. On our approach, a
monolingual teacher model is trained for each language/locale, and these
individual models are distilled into a single multilingual student model
intended to serve all languages/locales. In experiments using open-source data
as well as user data from a worldwide search service, we show that this leads
to highly effective spelling correction models that can meet the tight latency
requirements of deployed services.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">GPT</span> in Data Science: A Practical Exploration of Model Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11516v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11516v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathalia Nascimento, Cristina Tavares, Paulo Alencar, Donald Cowan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is an increasing interest in leveraging Large Language Models (LLMs)
for managing structured data and enhancing data science processes. Despite the
potential benefits, this integration poses significant questions regarding
their reliability and decision-making methodologies. It highlights the
importance of various factors in the model selection process, including the
nature of the data, problem type, performance metrics, computational resources,
interpretability vs accuracy, assumptions about data, and ethical
considerations. Our objective is to elucidate and express the factors and
assumptions guiding GPT-4's model selection recommendations. We employ a
variability model to depict these factors and use toy datasets to evaluate both
the model and the implementation of the identified heuristics. By contrasting
these outcomes with heuristics from other platforms, our aim is to determine
the effectiveness and distinctiveness of GPT-4's methodology. This research is
committed to advancing our comprehension of AI decision-making processes,
especially in the realm of model selection within data science. Our efforts are
directed towards creating AI systems that are more transparent and
comprehensible, contributing to a more responsible and efficient practice in
data science.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages. To appear in IEEE BigData 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Token-Level Adversarial <span class="highlight-title">Prompt</span> Detection Based on Perplexity Measures
  and Contextual Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengmian Hu, Gang Wu, Saayan Mitra, Ruiyi Zhang, Tong Sun, Heng Huang, Vishy Swaminathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Large Language Models (LLM) have emerged as pivotal tools in
various applications. However, these models are susceptible to adversarial
prompt attacks, where attackers can carefully curate input strings that lead to
undesirable outputs. The inherent vulnerability of LLMs stems from their
input-output mechanisms, especially when presented with intensely
out-of-distribution (OOD) inputs. This paper proposes a token-level detection
method to identify adversarial prompts, leveraging the LLM's capability to
predict the next token's probability. We measure the degree of the model's
perplexity and incorporate neighboring token information to encourage the
detection of contiguous adversarial prompt sequences. As a result, we propose
two methods: one that identifies each token as either being part of an
adversarial prompt or not, and another that estimates the probability of each
token being part of an adversarial prompt.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta <span class="highlight-title">Prompt</span>ing for AGI Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an in-depth exploration of Meta Prompting, a novel
technique that revolutionizes the way large language models (LLMs), multi-modal
foundation models, and AI systems approach problem-solving and data
interpretation. Meta Prompting, rooted in type theory and category theory,
prioritizes the structure and syntax of information, providing a unique
framework that transcends traditional content-focused methods. We delve into
the formal definitions of Meta Prompting, contrasting it with Few-Shot
Prompting, and highlight its applicability and superiority in various AI
applications.
  Key to this exploration is the expansion of Meta Prompting into the realm of
complex reasoning. Here, we demonstrate how this technique adeptly breaks down
intricate problems into manageable sub-problems, facilitating a step-by-step,
detailed approach to problem-solving. This method proves especially
advantageous in terms of token efficiency and offering a fair comparison in
problem-solving scenarios, standing out against few-shot example approaches.
  Furthermore, the paper breaks new ground by extending Meta Prompting into
multi-modal foundation model settings. This extension addresses the integration
of diverse data types, such as images, audio, and video, within the structured
framework of Meta Prompting, highlighting both the challenges and the vast
potential of this approach in handling complex, multi-faceted data (The code is
available at https://github.com/meta-prompting/meta-prompting).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What's left can't be right -- The remaining positional incompetence of
  contrastive vision-language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nils Hoehing, Ellen Rushe, Anthony Ventresque
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive vision-language models like CLIP have been found to lack spatial
understanding capabilities. In this paper we discuss the possible causes of
this phenomenon by analysing both datasets and embedding space. By focusing on
simple left-right positional relations, we show that this behaviour is entirely
predictable, even with large-scale datasets, demonstrate that these relations
can be taught using synthetic data and show that this approach can generalise
well to natural images - improving the performance on left-right relations on
Visual Genome Relations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lost in the Middle: How Language Models Use Long Contexts <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.03172v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.03172v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While recent language models have the ability to take long contexts as input,
relatively little is known about how well they use longer context. We analyze
the performance of language models on two tasks that require identifying
relevant information in their input contexts: multi-document question answering
and key-value retrieval. We find that performance can degrade significantly
when changing the position of relevant information, indicating that current
language models do not robustly make use of information in long input contexts.
In particular, we observe that performance is often highest when relevant
information occurs at the beginning or end of the input context, and
significantly degrades when models must access relevant information in the
middle of long contexts, even for explicitly long-context models. Our analysis
provides a better understanding of how language models use their input context
and provides new evaluation protocols for future long-context language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 16 figures. Accepted for publication in Transactions of the
  Association for Computational Linguistics (TACL), 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Contamination Quiz: A Tool to Detect and Estimate Contamination in
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.06233v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.06233v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahriar Golchin, Mihai Surdeanu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose the Data Contamination Quiz, a simple and effective approach to
detect data contamination in large language models (LLMs) and estimate the
amount of it. Specifically, we frame data contamination detection as a series
of multiple-choice questions. We devise a quiz format wherein three perturbed
versions of each dataset instance are created. These changes only include
word-level perturbations, replacing words with their contextual synonyms,
ensuring both the semantic and sentence structure remain exactly the same as
the original instance. Together with the original instance, these perturbed
versions constitute the choices in the quiz. Given that the only distinguishing
signal among these choices is the exact wording, an LLM, when tasked with
identifying the original instance from the choices, opts for the original if it
has memorized it in its pre-training phase--a trait intrinsic to LLMs. A
dataset partition is then marked as contaminated if the LLM's performance on
the quiz surpasses what random chance suggests. Our evaluation spans seven
datasets and their respective splits (train and test/validation) on two
state-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the
pre-training data, our results suggest that our approach not only enhances the
detection of data contamination but also provides an accurate estimation of its
extent, even when the contamination signal is weak.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v1.2 preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Antibody Design for Complementary Chain Pairing Sequences
  through Encoder-Decoder Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.02748v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.02748v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon K. S. Chu, Kathy Y. Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current protein language models (pLMs) predominantly focus on single-chain
protein sequences and often have not accounted for constraints on generative
design imposed by protein-protein interactions. To address this gap, we present
paired Antibody T5 (pAbT5), an encoder-decoder model to generate complementary
heavy or light chain from its pairing partner. We show that our model respects
conservation in framework regions and variability in hypervariable domains,
demonstrated by agreement with sequence alignment and variable-length CDR
loops. We also show that our model captures chain pairing preferences through
the recovery of ground-truth chain type and gene families. Our results showcase
the potential of pAbT5 in generative antibody design, incorporating biological
constraints from chain pairing preferences.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Ended Instructable Embodied Agents with Memory-Augmented Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.15127v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.15127v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Sarch, Yue Wu, Michael J. Tarr, Katerina Fragkiadaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained and frozen large language models (LLMs) can effectively map
simple scene rearrangement instructions to programs over a robot's visuomotor
functions through appropriate few-shot example prompting. To parse open-domain
natural language and adapt to a user's idiosyncratic procedures, not known
during prompt engineering time, fixed prompts fall short. In this paper, we
introduce HELPER, an embodied agent equipped with an external memory of
language-program pairs that parses free-form human-robot dialogue into action
programs through retrieval-augmented LLM prompting: relevant memories are
retrieved based on the current dialogue, instruction, correction, or VLM
description, and used as in-context prompt examples for LLM querying. The
memory is expanded during deployment to include pairs of user's language and
action plans, to assist future inferences and personalize them to the user's
language and routines. HELPER sets a new state-of-the-art in the TEACh
benchmark in both Execution from Dialog History (EDH) and Trajectory from
Dialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for
TfD. Our models, code, and video results can be found in our project's website:
https://helper-agent-llm.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page with code & videos: https://helper-agent-llm.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Language and Its Dimensions: Intrinsic Dimensions of Language Fractal
  Structures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10217v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10217v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vasilii A. Gromov, Nikita S. Borodin, Asel S. Yerbolova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The present paper introduces a novel object of study - a language fractal
structure. We hypothesize that a set of embeddings of all $n$-grams of a
natural language constitutes a representative sample of this fractal set. (We
use the term Hailonakea to refer to the sum total of all language fractal
structures, over all $n$). The paper estimates intrinsic (genuine) dimensions
of language fractal structures for the Russian and English languages. To this
end, we employ methods based on (1) topological data analysis and (2) a minimum
spanning tree of a data graph for a cloud of points considered (Steele
theorem). For both languages, for all $n$, the intrinsic dimensions appear to
be non-integer values (typical for fractal sets), close to 9 for both of the
Russian and English language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Varieties of Italy: Technology Challenges and Opportunities <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.09757v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.09757v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alan Ramponi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Italy is characterized by a one-of-a-kind linguistic diversity landscape in
Europe, which implicitly encodes local knowledge, cultural traditions, artistic
expressions and history of its speakers. However, most local languages and
dialects in Italy are at risk of disappearing within few generations. The NLP
community has recently begun to engage with endangered languages, including
those of Italy. Yet, most efforts assume that these varieties are
under-resourced language monoliths with an established written form and
homogeneous functions and needs, and thus highly interchangeable with each
other and with high-resource, standardized languages. In this paper, we
introduce the linguistic context of Italy and challenge the default
machine-centric assumptions of NLP for Italy's language varieties. We advocate
for a shift in the paradigm from machine-centric to speaker-centric NLP, and
provide recommendations and opportunities for work that prioritizes languages
and their speakers over technological advances. To facilitate the process, we
finally propose building a local community towards responsible, participatory
efforts aimed at supporting vitality of languages and dialects of Italy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to TACL. This arXiv version is a pre-MIT Press publication
  version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised Opinion Summarization Using Approximate Geodesics <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.07496v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.07496v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somnath Basu Roy Chowdhury, Nicholas Monath, Avinava Dubey, Amr Ahmed, Snigdha Chaturvedi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Opinion summarization is the task of creating summaries capturing popular
opinions from user reviews. In this paper, we introduce Geodesic Summarizer
(GeoSumm), a novel system to perform unsupervised extractive opinion
summarization. GeoSumm involves an encoder-decoder based representation
learning model, that generates representations of text as a distribution over
latent semantic units. GeoSumm generates these representations by performing
dictionary learning over pre-trained text representations at multiple decoder
layers. We then use these representations to quantify the relevance of review
sentences using a novel approximate geodesic distance based scoring mechanism.
We use the relevance scores to identify popular opinions in order to compose
general and aspect-specific summaries. Our proposed model, GeoSumm, achieves
state-of-the-art performance on three opinion summarization datasets. We
perform additional experiments to analyze the functioning of our model and
showcase the generalization ability of {\X} across different domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MEAL: Stable and Active Learning for Few-Shot <span class="highlight-title">Prompt</span>ing <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.08358v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.08358v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullatif Köksal, Timo Schick, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Few-shot classification has made great strides due to foundation models that,
through priming and prompting, are highly effective few-shot learners. However,
this approach has high variance both across different sets of few shots (data
selection) and across different finetuning runs (run variability). This is
problematic not only because it impedes the fair comparison of different
approaches, but especially because it makes few-shot learning too unreliable
for many real-world applications. To alleviate these issues, we make two
contributions for more stable and effective few-shot learning: First, we
propose novel ensembling methods and show that they substantially reduce run
variability. Second, we introduce a new active learning (AL) criterion for data
selection and present the first AL-based approach specifically tailored towards
prompt-based learning. In our experiments, we show that our combined method,
MEAL (Multiprompt finetuning and prediction Ensembling with Active Learning),
improves overall performance of prompt-based finetuning by 2.3 points on five
diverse tasks. We publicly share our code and data splits in
https://github.com/akoksal/MEAL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language-Agnostic Bias Detection in Language Models with Bias Probing <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.13302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.13302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullatif Köksal, Omer Faruk Yalcin, Ahmet Akbiyik, M. Tahir Kilavuz, Anna Korhonen, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretrained language models (PLMs) are key components in NLP, but they contain
strong social biases. Quantifying these biases is challenging because current
methods focusing on fill-the-mask objectives are sensitive to slight changes in
input. To address this, we propose a bias probing technique called LABDet, for
evaluating social bias in PLMs with a robust and language-agnostic method. For
nationality as a case study, we show that LABDet `surfaces' nationality bias by
training a classifier on top of a frozen PLM on non-nationality sentiment
detection. We find consistent patterns of nationality bias across monolingual
PLMs in six languages that align with historical and political context. We also
show for English BERT that bias surfaced by LABDet correlates well with bias in
the pretraining data; thus, our work is one of the few studies that directly
links pretraining data to PLM behavior. Finally, we verify LABDet's reliability
and applicability to different templates and languages through an extensive set
of robustness checks. We publicly share our code and dataset in
https://github.com/akoksal/LABDet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.15363v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.15363v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, Jingren Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL
task. However, the absence of a systematical benchmark inhibits the development
of designing effective, efficient and economic LLM-based Text-to-SQL solutions.
To address this challenge, in this paper, we first conduct a systematical and
extensive comparison over existing prompt engineering methods, including
question representation, example selection and example organization, and with
these experimental results, we elaborate their pros and cons. Based on these
findings, we propose a new integrated solution, named DAIL-SQL, which refreshes
the Spider leaderboard with 86.6% execution accuracy and sets a new bar. To
explore the potential of open-source LLM, we investigate them in various
scenarios, and further enhance their performance with supervised fine-tuning.
Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well
as the advantages and disadvantages of the supervised fine-tuning.
Additionally, towards an efficient and economic LLM-based Text-to-SQL solution,
we emphasize the token efficiency in prompt engineering and compare the prior
studies under this metric. We hope that our work provides a deeper
understanding of Text-to-SQL with LLMs, and inspires further investigations and
broad applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We have released code on https://github.com/BeachWang/DAIL-SQL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A novel approach to measuring patent claim scope based on probabilities
  obtained from (large) language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10003v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10003v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sébastien Ragot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work proposes to measure the scope of a patent claim as the reciprocal
of the self-information contained in this claim. A probability of occurrence of
the claim is obtained from a language model and this probability is used to
compute the self-information. Grounded in information theory, this approach is
based on the assumption that an unlikely concept is more informative than a
usual concept, insofar as it is more surprising. In turn, the more surprising
the information required to defined the claim, the narrower its scope. Five
language models are considered, ranging from simplest models (each word or
character is assigned an identical probability) to intermediate models (using
average word or character frequencies), to a large language model (GPT2).
Interestingly, the scope resulting from the simplest language models is
proportional to the reciprocal of the number of words or characters involved in
the claim, a metric already used in previous works. Application is made to
multiple series of patent claims directed to distinct inventions, where each
series consists of claims devised to have a gradually decreasing scope. The
performance of the language models is assessed with respect to several ad hoc
tests. The more sophisticated the model, the better the results. I.e., the GPT2
probability model outperforms models based on word and character frequencies,
which themselves outdo the simplest models based on word or character counts.
Still, the character count appears to be a more reliable indicator than the
word count.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>58 pages, 8 tables, 6 figures. Substantial changes made to version 2:
  New section 4.1 added (including a new table); Minor normalization issue
  corrected in values listed in Appendix B; Content of former appendix C now
  moved to Section 3; and new Appendix C added. Minor changes made to version 3
  (style, typos, language)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Women Wearing Lipstick: Measuring the Bias Between an Object and Its
  Related Gender <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.19130v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.19130v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Sabir, Lluís Padró
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the impact of objects on gender bias in image
captioning systems. Our results show that only gender-specific objects have a
strong gender bias (e.g., women-lipstick). In addition, we propose a visual
semantic-based gender score that measures the degree of bias and can be used as
a plug-in for any image captioning system. Our experiments demonstrate the
utility of the gender score, since we observe that our score can measure the
bias relation between a caption and its related gender; therefore, our score
can be used as an additional metric to the existing Object Gender Co-Occ
approach. Code and data are publicly available at
\url{https://github.com/ahmedssabir/GenderScore}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP Findings 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Attribution Patching Outperforms Automated Circuit Discovery <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.10348v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.10348v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaquib Syed, Can Rager, Arthur Conmy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated interpretability research has recently attracted attention as a
potential research direction that could scale explanations of neural network
behavior to large models. Existing automated circuit discovery work applies
activation patching to identify subnetworks responsible for solving specific
tasks (circuits). In this work, we show that a simple method based on
attribution patching outperforms all existing methods while requiring just two
forward passes and a backward pass. We apply a linear approximation to
activation patching to estimate the importance of each edge in the
computational subgraph. Using this approximation, we prune the least important
edges of the network. We survey the performance and limitations of this method,
finding that averaged over all tasks our method has greater AUC from circuit
recovery than other methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 main paper pages, 6 additional pages. NeurIPS 2023 ATTRIB Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StyleTTS: A Style-Based Generative Model for Natural and Diverse
  Text-to-Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2205.15439v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2205.15439v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinghao Aaron Li, Cong Han, Nima Mesgarani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-Speech (TTS) has recently seen great progress in synthesizing
high-quality speech owing to the rapid development of parallel TTS systems, but
producing speech with naturalistic prosodic variations, speaking styles and
emotional tones remains challenging. Moreover, since duration and speech are
generated separately, parallel TTS models still have problems finding the best
monotonic alignments that are crucial for naturalistic speech synthesis. Here,
we propose StyleTTS, a style-based generative model for parallel TTS that can
synthesize diverse speech with natural prosody from a reference speech
utterance. With novel Transferable Monotonic Aligner (TMA) and
duration-invariant data augmentation schemes, our method significantly
outperforms state-of-the-art models on both single and multi-speaker datasets
in subjective tests of speech naturalness and speaker similarity. Through
self-supervised learning of the speaking styles, our model can synthesize
speech with the same prosodic and emotional tone as any given reference speech
without the need for explicitly labeling these categories.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion
  and Adversarial Training with Large Speech Language Models <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.07691v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.07691v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima Mesgarani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that
leverages style diffusion and adversarial training with large speech language
models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its
predecessor by modeling styles as a latent random variable through diffusion
models to generate the most suitable style for the text without requiring
reference speech, achieving efficient latent diffusion while benefiting from
the diverse speech synthesis offered by diffusion models. Furthermore, we
employ large pre-trained SLMs, such as WavLM, as discriminators with our novel
differentiable duration modeling for end-to-end training, resulting in improved
speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker
LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by
native English speakers. Moreover, when trained on the LibriTTS dataset, our
model outperforms previous publicly available models for zero-shot speaker
adaptation. This work achieves the first human-level TTS on both single and
multispeaker datasets, showcasing the potential of style diffusion and
adversarial training with large SLMs. The audio demos and source code are
available at https://styletts2.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transferring Procedural Knowledge across Commonsense Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.13867v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.13867v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifan Jiang, Filip Ilievski, Kaixin Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stories about everyday situations are an essential part of human
communication, motivating the need to develop AI agents that can reliably
understand these stories. Despite the long list of supervised methods for story
completion and procedural understanding, current AI has no mechanisms to
automatically track and explain procedures in unseen stories. To bridge this
gap, we study the ability of AI models to transfer procedural knowledge to
novel narrative tasks in a transparent manner. We design LEAP: a comprehensive
framework that integrates state-of-the-art modeling architectures, training
regimes, and augmentation strategies based on both natural and synthetic
stories. To address the lack of densely annotated training data, we devise a
robust automatic labeler based on few-shot prompting to enhance the augmented
data. Our experiments with in- and out-of-domain tasks reveal insights into the
interplay of different architectures, training regimes, and augmentation
strategies. LEAP's labeler has a clear positive impact on out-of-domain
datasets, while the resulting dense annotation provides native explainability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Solving Math Word Problems with Reexamination <span class="chip">NeurIPS2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09590v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09590v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Bin, Wenhao Shi, Yujuan Ding, Yang Yang, See-Kiong Ng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Math word problem (MWP) solving aims to understand the descriptive math
problem and calculate the result, for which previous efforts are mostly devoted
to upgrade different technical modules. This paper brings a different
perspective of \textit{reexamination process} during training by introducing a
pseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual)
learning scheme to model such process, which is model-agnostic thus can be
adapted to any existing MWP solvers. The pseudo-dual task is specifically
defined as filling the numbers in the expression back into the original word
problem with numbers masked. To facilitate the effective joint learning of the
two tasks, we further design a scheduled fusion strategy for the number
infilling task, which smoothly switches the input from the ground-truth math
expressions to the predicted ones. Our pseudo-dual learning scheme has been
tested and proven effective when being equipped in several representative MWP
solvers through empirical studies. \textit{The codes and trained models are
available at:} \url{https://github.com/steven640pixel/PsedualMWP}.
\end{abstract}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be appeared at NeurIPS2023 Workshop on MATH-AI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10702v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10702v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah A. Smith, Iz Beltagy, Hannaneh Hajishirzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since the release of T\"ULU [Wang et al., 2023b], open resources for
instruction tuning have developed quickly, from better base models to new
finetuning techniques. We test and incorporate a number of these advances into
T\"ULU, resulting in T\"ULU 2, a suite of improved T\"ULU models for advancing
the understanding and best practices of adapting pretrained language models to
downstream tasks and user preferences. Concretely, we release: (1)
T\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)
T\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\"ULU 2+DPO, T\"ULU
2 models trained with direct preference optimization (DPO), including the
largest DPO-trained model to date (T\"ULU 2+DPO 70B); (4) CODE T\"ULU 2, CODE
LLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its
instruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple
perspectives shows that the T\"ULU 2 suite achieves state-of-the-art
performance among open models and matches or exceeds the performance of
GPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,
training and evaluation code to facilitate future open efforts on adapting
large language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>technical report; fixed zephyr numbers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Effective Proxy for Human Labeling: Ensemble Disagreement Scores in
  Large Language Models for Industrial NLP <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.05619v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.05619v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Du, Laksh Advani, Yashmeet Gambhir, Daniel J Perry, Prashant Shiralkar, Zhengzheng Xing, Aaron Colak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated significant capability to
generalize across a large number of NLP tasks. For industry applications, it is
imperative to assess the performance of the LLM on unlabeled production data
from time to time to validate for a real-world setting. Human labeling to
assess model error requires considerable expense and time delay. Here we
demonstrate that ensemble disagreement scores work well as a proxy for human
labeling for language models in zero-shot, few-shot, and fine-tuned settings,
per our evaluation on keyphrase extraction (KPE) task. We measure fidelity of
the results by comparing to true error measured from human labeled ground
truth. We contrast with the alternative of using another LLM as a source of
machine labels, or silver labels. Results across various languages and domains
show disagreement scores provide a better estimation of model performance with
mean average error (MAE) as low as 0.4% and on average 13.8% better than using
silver labels.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera ready version for 2023 EMNLP (The Third Workshop on Natural
  Language Generation, Evaluation, and Metrics (GEM))</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Landmark Attention: Random-Access Infinite Context Length for
  <span class="highlight-title">Transformer</span>s <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.16300v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.16300v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirkeivan Mohtashami, Martin Jaggi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Transformers have shown remarkable success in natural language
processing, their attention mechanism's large memory requirements have limited
their ability to handle longer contexts. Prior approaches, such as recurrent
memory or retrieval-based augmentation, have either compromised the
random-access flexibility of attention (i.e., the capability to select any
token in the entire context) or relied on separate mechanisms for relevant
context retrieval, which may not be compatible with the model's attention. In
this paper, we present a novel approach that allows access to the complete
context while retaining random-access flexibility, closely resembling running
attention on the entire context. Our method uses a landmark token to represent
each block of the input and trains the attention to use it for selecting
relevant blocks, enabling retrieval of blocks directly through the attention
mechanism instead of by relying on a separate mechanism. Our approach
seamlessly integrates with specialized data structures and the system's memory
hierarchy, enabling processing of arbitrarily long context lengths. We
demonstrate that our method can obtain comparable performance with
Transformer-XL while significantly reducing the number of retrieved tokens in
each step. Finally, we show that fine-tuning LLaMA 7B with our method
successfully extends its context length capacity to over 32k tokens, allowing
for inference at the context lengths of GPT-4. We release the implementation of
landmark attention and the code to reproduce our experiments at
https://github.com/epfml/landmark-attention/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at NeurIPS 2023 - 37th Conference on
  Neural Information Processing Systems</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2023-11-19T00:00:00Z">2023-11-19</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM aided semi-supervision for Extractive Dialog Summarization <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishant Mishra, Gaurav Sahu, Iacer Calixto, Ameen Abu-Hanna, Issam H. Laradji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating high-quality summaries for chat dialogs often requires large
labeled datasets. We propose a method to efficiently use unlabeled data for
extractive summarization of customer-agent dialogs. In our method, we frame
summarization as a question-answering problem and use state-of-the-art large
language models (LLMs) to generate pseudo-labels for a dialog. We then use
these pseudo-labels to fine-tune a chat summarization model, effectively
transferring knowledge from the large LLM into a smaller specialized model. We
demonstrate our method on the \tweetsumm dataset, and show that using 10\% of
the original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L,
whereas the current state-of-the-art trained on the entire training data set
obtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case
(i.e., ROUGE-L) we still effectively retain 94.7% of the performance while
using only 10% of the data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>to be published in EMNLP Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spot the Bot: Distinguishing Human-Written and Bot-Generated Texts Using
  Clustering and Information Theory Techniques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vasilii Gromov, Quynh Nhu Dang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the development of generative models like GPT-3, it is increasingly more
challenging to differentiate generated texts from human-written ones. There is
a large number of studies that have demonstrated good results in bot
identification. However, the majority of such works depend on supervised
learning methods that require labelled data and/or prior knowledge about the
bot-model architecture. In this work, we propose a bot identification algorithm
that is based on unsupervised learning techniques and does not depend on a
large amount of labelled data. By combining findings in semantic analysis by
clustering (crisp and fuzzy) and information techniques, we construct a robust
model that detects a generated text for different types of bot. We find that
the generated texts tend to be more chaotic while literary works are more
complex. We also demonstrate that the clustering of human texts results in
fuzzier clusters in comparison to the more compact and well-separated clusters
of bot-generated texts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in Pattern Recognition and Machine Intelligence 2023. 8
  pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis
  of COVID-19 Vaccines in India 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milind Gupta, Abhishek Kaushik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In March 2020, the World Health Organisation declared COVID-19 a global
pandemic as it spread to nearly every country. By mid-2021, India had
introduced three vaccines: Covishield, Covaxin, and Sputnik. To ensure
successful vaccination in a densely populated country like India, understanding
public sentiment was crucial. Social media, particularly Reddit with over 430
million users, played a vital role in disseminating information. This study
employs data mining techniques to analyze Reddit data and gauge Indian
sentiments towards COVID-19 vaccines. Using Python's Text Blob library,
comments are annotated to assess general sentiments. Results show that most
Reddit users in India expressed neutrality about vaccination, posing a
challenge for the Indian government's efforts to vaccinate a significant
portion of the population.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Security Risk Taxonomy for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11415v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11415v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Derner, Kristina Batistič, Jan Zahálka, Robert Babuška
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) permeate more and more applications, an
assessment of their associated security risks becomes increasingly necessary.
The potential for exploitation by malicious actors, ranging from disinformation
to data breaches and reputation damage, is substantial. This paper addresses a
gap in current research by focusing on the security risks posed by LLMs, which
extends beyond the widely covered ethical and societal implications. Our work
proposes a taxonomy of security risks along the user-model communication
pipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize
the attacks by target and attack type within a prompt-based interaction scheme.
The taxonomy is reinforced with specific attack examples to showcase the
real-world impact of these risks. Through this taxonomy, we aim to inform the
development of robust and secure LLM applications, enhancing their safety and
trustworthiness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for
  Improving ASR Robustness in Spoken Language Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuxin Cheng, Bowen Cao, Qichen Ye, Zhihong Zhu, Hongxiang Li, Yuexian Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spoken language understanding (SLU) is a fundamental task in the
task-oriented dialogue systems. However, the inevitable errors from automatic
speech recognition (ASR) usually impair the understanding performance and lead
to error propagation. Although there are some attempts to address this problem
through contrastive learning, they (1) treat clean manual transcripts and ASR
transcripts equally without discrimination in fine-tuning; (2) neglect the fact
that the semantically similar pairs are still pushed away when applying
contrastive learning; (3) suffer from the problem of Kullback-Leibler (KL)
vanishing. In this paper, we propose Mutual Learning and Large-Margin
Contrastive Learning (ML-LMCL), a novel framework for improving ASR robustness
in SLU. Specifically, in fine-tuning, we apply mutual learning and train two
SLU models on the manual transcripts and the ASR transcripts, respectively,
aiming to iteratively share knowledge between these two models. We also
introduce a distance polarization regularizer to avoid pushing away the
intra-cluster pairs as much as possible. Moreover, we use a cyclical annealing
schedule to mitigate KL vanishing issue. Experiments on three datasets show
that ML-LMCL outperforms existing models and achieves new state-of-the-art
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Portuguese FAQ for Financial Services 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paulo Finardi, Wanderley M. Melo, Edgard D. Medeiros Neto, Alex F. Mansano, Pablo B. Costa, Vinicius F. Caridá
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scarcity of domain-specific data in the Portuguese financial domain has
disfavored the development of Natural Language Processing (NLP) applications.
To address this limitation, the present study advocates for the utilization of
synthetic data generated through data augmentation techniques. The
investigation focuses on the augmentation of a dataset sourced from the Central
Bank of Brazil FAQ, employing techniques that vary in semantic similarity.
Supervised and unsupervised tasks are conducted to evaluate the impact of
augmented data on both low and high semantic similarity scenarios.
Additionally, the resultant dataset will be publicly disseminated on the
Hugging Face Datasets platform, thereby enhancing accessibility and fostering
broader engagement within the NLP research community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CHAMP: Efficient Annotation and Consolidation of Cluster Hierarchies <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11301v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11301v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arie Cattan, Tom Hope, Doug Downey, Roy Bar-Haim, Lilach Eden, Yoav Kantor, Ido Dagan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various NLP tasks require a complex hierarchical structure over nodes, where
each node is a cluster of items. Examples include generating entailment graphs,
hierarchical cross-document coreference resolution, annotating event and
subevent relations, etc. To enable efficient annotation of such hierarchical
structures, we release CHAMP, an open source tool allowing to incrementally
construct both clusters and hierarchy simultaneously over any type of texts.
This incremental approach significantly reduces annotation time compared to the
common pairwise annotation approach and also guarantees maintaining
transitivity at the cluster and hierarchy levels. Furthermore, CHAMP includes a
consolidation mode, where an adjudicator can easily compare multiple cluster
hierarchy annotations and resolve disagreements.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Cross-Attention Augmented Model for Event-Triggered Context-Aware
  Story Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Tang, Tyler Loakman, Chenghua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent advancements, existing story generation systems continue to
encounter difficulties in effectively incorporating contextual and event
features, which greatly influence the quality of generated narratives. To
tackle these challenges, we introduce a novel neural generation model, EtriCA,
that enhances the relevance and coherence of generated stories by employing a
cross-attention mechanism to map context features onto event sequences through
residual mapping. This feature capturing mechanism enables our model to exploit
logical relationships between events more effectively during the story
generation process. To further enhance our proposed model, we employ a
post-training framework for knowledge enhancement (KeEtriCA) on a large-scale
book corpus. This allows EtriCA to adapt to a wider range of data samples. This
results in approximately 5\% improvement in automatic metrics and over 10\%
improvement in human evaluation. We conduct extensive experiments, including
comparisons with state-of-the-art (SOTA) baseline models, to evaluate the
performance of our framework on story generation. The experimental results,
encompassing both automated metrics and human assessments, demonstrate the
superiority of our model over existing state-of-the-art baselines. These
results underscore the effectiveness of our model in leveraging context and
event features to improve the quality of generated narratives.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to CSL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Real-World Writing Assistance: A <span class="highlight-title">Chinese</span> Character Checking
  Benchmark with Faked and Misspelled Characters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yinghui Li, Zishan Xu, Shaoshen Chen, Haojing Huang, Yangning Li, Yong Jiang, Zhongli Li, Qingyu Zhou, Hai-Tao Zheng, Ying Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Writing assistance is an application closely related to human life and is
also a fundamental Natural Language Processing (NLP) research field. Its aim is
to improve the correctness and quality of input texts, with character checking
being crucial in detecting and correcting wrong characters. From the
perspective of the real world where handwriting occupies the vast majority,
characters that humans get wrong include faked characters (i.e., untrue
characters created due to writing errors) and misspelled characters (i.e., true
characters used incorrectly due to spelling errors). However, existing datasets
and related studies only focus on misspelled characters mainly caused by
phonological or visual confusion, thereby ignoring faked characters which are
more common and difficult. To break through this dilemma, we present
Visual-C$^3$, a human-annotated Visual Chinese Character Checking dataset with
faked and misspelled Chinese characters. To the best of our knowledge,
Visual-C$^3$ is the first real-world visual and the largest human-crafted
dataset for the Chinese character checking scenario. Additionally, we also
propose and evaluate novel baseline methods on Visual-C$^3$. Extensive
empirical results and analyses show that Visual-C$^3$ is high-quality yet
challenging. The Visual-C$^3$ dataset and the baseline methods will be publicly
available to facilitate further research in the community.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Large Language Models in Mental Health Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11267v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11267v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have become valuable assets in mental health,
showing promise in both classification tasks and counseling applications. This
paper offers a perspective on using LLMs in mental health applications. It
discusses the instability of generative models for prediction and the potential
for generating hallucinatory outputs, underscoring the need for ongoing audits
and evaluations to maintain their reliability and dependability. The paper also
distinguishes between the often interchangeable terms ``explainability'' and
``interpretability'', advocating for developing inherently interpretable
methods instead of relying on potentially hallucinated self-explanations
generated by LLMs. Despite the advancements in LLMs, human counselors'
empathetic understanding, nuanced interpretation, and contextual awareness
remain irreplaceable in the sensitive and complex realm of mental health
counseling. The use of LLMs should be approached with a judicious and
considerate mindset, viewing them as tools that complement human expertise
rather than seeking to replace it.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causal ATE Mitigates Unintended Bias in Controlled Text Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11229v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11229v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rahul Madhavan, Kahini Wadhawan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study attribute control in language models through the method of Causal
Average Treatment Effect (Causal ATE). Existing methods for the attribute
control task in Language Models (LMs) check for the co-occurrence of words in a
sentence with the attribute of interest, and control for them. However,
spurious correlation of the words with the attribute in the training dataset,
can cause models to hallucinate the presence of the attribute when presented
with the spurious correlate during inference. We show that the simple
perturbation-based method of Causal ATE removes this unintended effect.
Additionally, we offer a theoretical foundation for investigating Causal ATE in
the classification task, and prove that it reduces the number of false
positives -- thereby mitigating the issue of unintended bias. Specifically, we
ground it in the problem of toxicity mitigation, where a significant challenge
lies in the inadvertent bias that often emerges towards protected groups post
detoxification. We show that this unintended bias can be solved by the use of
the Causal ATE metric.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SPLAIN: Augmenting CybersecurityWarnings with Reasons and Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11215v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11215v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vera A. Kazakova, Jena D. Hwang, Bonnie J. Dorr, Yorick Wilks, J. Blake Gage, Alex Memory, Mark A. Clark
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective cyber threat recognition and prevention demand comprehensible
forecasting systems, as prior approaches commonly offer limited and,
ultimately, unconvincing information. We introduce Simplified Plaintext
Language (SPLAIN), a natural language generator that converts warning data into
user-friendly cyber threat explanations. SPLAIN is designed to generate clear,
actionable outputs, incorporating hierarchically organized explanatory details
about input data and system functionality. Given the inputs of individual
sensor-induced forecasting signals and an overall warning from a fusion module,
SPLAIN queries each signal for information on contributing sensors and data
signals. This collected data is processed into a coherent English explanation,
encompassing forecasting, sensing, and data elements for user review. SPLAIN's
template-based approach ensures consistent warning structure and vocabulary.
SPLAIN's hierarchical output structure allows each threat and its components to
be expanded to reveal underlying explanations on demand. Our conclusions
emphasize the need for designers to specify the "how" and "why" behind cyber
warnings, advocate for simple structured templates in generating consistent
explanations, and recognize that direct causal links in Machine Learning
approaches may not always be identifiable, requiring some explanations to focus
on general methodologies, such as model and training data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at FLAIRS-2019 as poster (see ancillary files)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unmasking and Improving Data Credibility: A Study with <span class="highlight-title">Dataset</span>s for
  Training Harmless Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11202v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11202v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaowei Zhu, Jialu Wang, Hao Cheng, Yang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models have shown promise in various tasks but can be affected by
undesired data during training, fine-tuning, or alignment. For example, if some
unsafe conversations are wrongly annotated as safe ones, the model fine-tuned
on these samples may be harmful. Therefore, the correctness of annotations,
i.e., the credibility of the dataset, is important. This study focuses on the
credibility of real-world datasets, including the popular benchmarks Jigsaw
Civil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that
can be used for training a harmless language model. Given the cost and
difficulty of cleaning these datasets by humans, we introduce a systematic
framework for evaluating the credibility of datasets, identifying label errors,
and evaluating the influence of noisy labels in the curated language data,
specifically focusing on unsafe comments and conversation classification. With
the framework, we find and fix an average of 6.16% label errors in 11 datasets
constructed from the above benchmarks. The data credibility and downstream
learning performance can be remarkably improved by directly fixing label
errors, indicating the significance of cleaning existing real-world datasets.
Open-source: https://github.com/Docta-ai/docta.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Large Language Models to Knowledge Graphs for Biomarker Discovery
  in Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.08365v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.08365v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md. Rezaul Karim, Lina Molinas Comet, Md Shajalal, Oya Deniz Beyan, Dietrich Rebholz-Schuhmann, Stefan Decker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain experts often rely on most recent knowledge for apprehending and
disseminating specific biological processes that help them design strategies
for developing prevention and therapeutic decision-making in various disease
scenarios. A challenging scenarios for artificial intelligence (AI) is using
biomedical data (e.g., texts, imaging, omics, and clinical) to provide
diagnosis and treatment recommendations for cancerous conditions.~Data and
knowledge about biomedical entities like cancer, drugs, genes, proteins, and
their mechanism is spread across structured (knowledge bases (KBs)) and
unstructured (e.g., scientific articles) sources. A large-scale knowledge graph
(KG) can be constructed by integrating and extracting facts about semantically
interrelated entities and relations. Such a KG not only allows exploration and
question answering (QA) but also enables domain experts to deduce new
knowledge. However, exploring and querying large-scale KGs is tedious for
non-domain users due to their lack of understanding of the data assets and
semantic technologies. In this paper, we develop a domain KG to leverage
cancer-specific biomarker discovery and interactive QA. For this, we
constructed a domain ontology called OncoNet Ontology (ONO), which enables
semantic reasoning for validating gene-disease (different types of cancer)
relations. The KG is further enriched by harmonizing the ONO, metadata,
controlled vocabularies, and biomedical concepts from scientific articles by
employing BioBERT- and SciBERT-based information extractors. Further, since the
biomedical domain is evolving, where new findings often replace old ones,
without having access to up-to-date scientific findings, there is a high chance
an AI system exhibits concept drift while providing diagnosis and treatment.
Therefore, we fine-tune the KG using large language models (LLMs) based on more
recent articles and KBs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2302.04737</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Chat<span class="highlight-title">GPT</span> a General-Purpose Natural Language Processing Task Solver? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.06476v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.06476v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Generation from Human Brain Activities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09889v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09889v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyi Ye, Qingyao Ai, Yiqun Liu, Min Zhang, Christina Lioma, Tuukka Ruotsalo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating human language through non-invasive brain-computer interfaces
(BCIs) has the potential to unlock many applications, such as serving disabled
patients and improving communication. Currently, however, generating language
via BCIs has been previously successful only within a classification setup for
selecting pre-generated sentence continuation candidates with the most likely
cortical semantic representation. Inspired by recent research that revealed
associations between the brain and the large computational language models, we
propose a generative language BCI that utilizes the capacity of a large
language model (LLM) jointly with a semantic brain decoder to directly generate
language from functional magnetic resonance imaging (fMRI) input. The proposed
model can generate coherent language sequences aligned with the semantic
content of visual or auditory language stimuli perceived, without prior
knowledge of any pre-generated candidates. We compare the language generated
from the presented model with a random control, pre-generated language
selection approach, and a standard LLM, which generates common coherent text
solely based on the next word likelihood according to statistical language
training data. The proposed model is found to generate language that is more
aligned with semantic stimulus in response to which brain input is sampled. Our
findings demonstrate the potential and feasibility of employing BCIs in direct
language generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under Submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning to Initialize: Can Meta Learning Improve Cross-task
  Generalization in <span class="highlight-title">Prompt</span> Tuning? <span class="chip">ACL2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.08143v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.08143v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengwei Qin, Qian Li, Ruochen Zhao, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt tuning (PT) which only tunes the embeddings of an additional sequence
of tokens per task, keeping the pre-trained language model (PLM) frozen, has
shown remarkable performance in few-shot learning. Despite this, PT has been
shown to rely heavily on good initialization of the prompt embeddings. In this
work, we study meta prompt tuning (MPT) to systematically explore how
meta-learning can help improve (if it can) cross-task generalization in PT
through learning to initialize the prompt embeddings from other relevant tasks.
We empirically analyze a representative set of meta learning algorithms in a
wide range of adaptation settings with different source/target task
configurations on a large set of few-shot tasks. With extensive experiments and
analysis, we demonstrate the effectiveness of MPT. We find the improvement to
be significant particularly on classification tasks. For other kinds of tasks
such as question answering, we observe that while MPT can outperform PT in most
cases, it does not always outperform multi-task learning. We further provide an
in-depth analysis from the perspective of task similarity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACL2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lifelong Sequence Generation with Dynamic Module Expansion and
  Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09886v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09886v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengwei Qin, Chen Chen, Shafiq Joty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lifelong sequence generation (LSG), a problem in continual learning, aims to
continually train a model on a sequence of generation tasks to learn constantly
emerging new generation patterns while avoiding the forgetting of previous
knowledge. Existing LSG methods mainly focus on maintaining old knowledge while
paying little attention to knowledge transfer across tasks. In contrast, humans
can better learn new tasks by leveraging previously acquired knowledge from
similar tasks. Inspired by the learning paradigm of humans, we propose Dynamic
Module Expansion and Adaptation (DMEA), which enables the model to dynamically
determine the architecture for acquiring new knowledge based on task
correlation and select the most similar previous tasks to facilitate adaptation
to new tasks. In addition, as the learning process can easily be biased towards
the current task which might cause more severe forgetting of previously learned
knowledge, we propose dynamic gradient scaling to balance the learning of the
current task and replayed tasks. With extensive experiments, we demonstrate
that DMEA can consistently outperform existing methods in different LSG
settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Investigating Uncertainty Calibration of Aligned Language Models under
  the Multiple-Choice Setting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11732v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11732v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guande He, Peng Cui, Jianfei Chen, Wenbo Hu, Jun Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant progress made in practical applications of aligned
language models (LMs), they tend to be overconfident in output answers compared
to the corresponding pre-trained LMs. In this work, we systematically evaluate
the impact of the alignment process on logit-based uncertainty calibration of
LMs under the multiple-choice setting. We first conduct a thoughtful empirical
study on how aligned LMs differ in calibration from their pre-trained
counterparts. Experimental results reveal that there are two distinct
uncertainties in LMs under the multiple-choice setting, which are responsible
for the answer decision and the format preference of the LMs, respectively.
Then, we investigate the role of these two uncertainties on aligned LM's
calibration through fine-tuning in simple synthetic alignment schemes and
conclude that one reason for aligned LMs' overconfidence is the conflation of
these two types of uncertainty. Furthermore, we examine the utility of common
post-hoc calibration methods for aligned LMs and propose an easy-to-implement
and sample-efficient method to calibrate aligned LMs. We hope our findings
could provide insights into the design of more reliable alignment processes for
LMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on Language Models for Code 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07989v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07989v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work we systematically review the recent advancements in code
processing with language models, covering 50+ models, 30+ evaluation tasks,
150+ datasets, and 550 related works. We break down code processing models into
general language models represented by the GPT family and specialized models
that are specifically pretrained on code, often with tailored objectives. We
discuss the relations and differences between these models, and highlight the
historical transition of code modeling from statistical models and RNNs to
pretrained Transformers and LLMs, which is exactly the same course that had
been taken by NLP. We also discuss code-specific features such as AST, CFG, and
unit tests, along with their application in training code language models, and
identify key challenges and potential future directions in this domain. We keep
the survey open and updated on GitHub repository at
https://github.com/codefuse-ai/Awesome-Code-LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Repo is available at https://github.com/codefuse-ai/Awesome-Code-LLM.
  V2 adds several new tasks, and collates dozens more benchmarks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IRFL: Image Recognition of Figurative Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.15445v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.15445v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ron Yosef, Yonatan Bitton, Dafna Shahaf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Figures of speech such as metaphors, similes, and idioms are integral parts
of human communication. They are ubiquitous in many forms of discourse,
allowing people to convey complex, abstract ideas and evoke emotion. As
figurative forms are often conveyed through multiple modalities (e.g., both
text and images), understanding multimodal figurative language is an important
AI challenge, weaving together profound vision, language, commonsense and
cultural knowledge.
  In this work, we develop the Image Recognition of Figurative Language (IRFL)
dataset. We leverage human annotation and an automatic pipeline we created to
generate a multimodal dataset, and introduce two novel tasks as a benchmark for
multimodal figurative language understanding. We experimented with
state-of-the-art vision and language models and found that the best (22%)
performed substantially worse than humans (97%). We release our dataset,
benchmark, and code, in hopes of driving the development of models that can
better understand figurative language.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalization Analogies: A Testbed for Generalizing AI Oversight to
  Hard-To-Measure Domains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07723v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07723v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Clymer, Garrett Baker, Rohan Subramani, Sam Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As AI systems become more intelligent and their behavior becomes more
challenging to assess, they may learn to game the flaws of human feedback
instead of genuinely striving to follow instructions; however, this risk can be
mitigated by controlling how LLMs generalize human feedback to situations where
it is unreliable. To better understand how reward models generalize, we craft
69 distribution shifts spanning 8 categories. We find that reward models do not
learn to evaluate `instruction-following' by default and instead favor personas
that resemble internet text. Techniques for interpreting reward models'
internal representations achieve better generalization than standard
fine-tuning, but still frequently fail to distinguish instruction-following
from conflated behaviors. We consolidate the 15 most challenging distribution
shifts into the GENeralization analogIES (GENIES) benchmark, which we hope will
enable progress toward controlling reward model generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/Joshuaclymer/GENIES Website:
  https://joshuaclymer.github.io/generalization-analogies-website/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How To Train Your (Compressed) Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ananya Harsh Jha, Tom Sherborne, Evan Pete Walsh, Dirk Groeneveld, Emma Strubell, Iz Beltagy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increase in the size of large language models (LLMs), we need
compression methods that can reduce the model size while preserving the
generality and zero-shot promptability of the model. This goal is more
ambitious than the typical compression setup, which reduces the model's size at
the expense of specializing it to a specific end-task. To study this, we
develop a task-agnostic compression pipeline with a large-scale evaluation
comprising language modeling perplexity and 12 zero-shot end-tasks. Our results
show that a simple layer-wise pruning followed by continued language model
pretraining matches or outperforms three existing state-of-the-art baselines
while being 1.5x more computationally efficient. However, unlike typical
task-specialized compression, our best-compressed model significantly
underperforms a similar-sized model trained from scratch. We posit the
half-sized pretrained model as an upper bound for task-agnostic compression and
call for future work to bridge this gap under a reasonable token budget. Our
findings highlight the inadequacy of existing compression methods for LLMs and
establish a requirement for new methods that preserve a model's generality and
zero-shot promptability under compression. We release our code and evaluation
setup to facilitate reproducibility and help iterate on method design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2023-11-18T00:00:00Z">2023-11-18</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Experts-in-the-Loop: Establishing an Effective Workflow in Crafting
  Privacy Q&A 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11161v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11161v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zahra Kolagar, Anna Katharina Leschanowsky, Birgit Popp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Privacy policies play a vital role in safeguarding user privacy as legal
jurisdictions worldwide emphasize the need for transparent data processing.
While the suitability of privacy policies to enhance transparency has been
critically discussed, employing conversational AI systems presents unique
challenges in informing users effectively. In this position paper, we propose a
dynamic workflow for transforming privacy policies into privacy
question-and-answer (Q&A) pairs to make privacy policies easily accessible
through conversational AI. Thereby, we facilitate interdisciplinary
collaboration among legal experts and conversation designers, while also
considering the utilization of large language models' generative capabilities
and addressing associated challenges. Our proposed workflow underscores
continuous improvement and monitoring throughout the construction of privacy
Q&As, advocating for comprehensive review and refinement through an
experts-in-the-loop approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Position paper presented at CONVERSATIONS 2023 - the 7th
  International Workshop on Chatbot Research and Design, hosted by the
  University of Oslo, Norway, November 22-23, 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating the Inclusiveness of Artificial Intelligence Software in
  Enhancing Project Management Efficiency -- A <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vasileios Alevizos, Ilias Georgousis, Akebu Simasiku, Sotiria Karypidou, Antonis Messinis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of advanced technology in project management (PM) highlights a
crucial need for inclusiveness. This work examines the enhancement of both
inclusivity and efficiency in PM through technological integration, focusing on
defining and measuring inclusiveness. This approach illuminates how
inclusivity-centered technology can significantly elevate project outcomes. The
research navigates through the challenges of achieving inclusivity, mainly
biases in learning databases and the design process of these technologies,
assessment of transformative potential of these technologies, particularly in
automating tasks like data collection and analysis, thus enabling managers to
prioritize human-centric aspects of projects. However, the integration of such
technology transcends efficiency, indicating a paradigm shift in understanding
their societal roles. This shift necessitates a new approach in the development
of these systems to prevent perpetuating social inequalities. We proposed a
methodology involving criteria development for evaluating the inclusiveness and
effectiveness of these technologies. This methodical approach is vital to
comprehensively address the challenges and limitations inherent in these
systems. Emphasizing the importance of inclusivity, the study advocates for a
balance between technological advancement and ethical considerations, calling
for a holistic understanding and regulation. In conclusion, the paper
underscores that while these technologies can significantly improve outcomes,
their mindful integration, ensuring inclusivity, is paramount. This exploration
into the ethical and practical aspects of technology in PM contributes to a
more informed and balanced approach within the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vashantor: A Large-scale Multilingual Benchmark <span class="highlight-title">Dataset</span> for Automated
  Translation of Bangla Regional Dialects to Bangla Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11142v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11142v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fatema Tuj Johora Faria, Mukaffi Bin Moin, Ahmed Al Wase, Mehidi Ahmmed, Md. Rabius Sani, Tashreef Muhammad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Bangla linguistic variety is a fascinating mix of regional dialects that
adds to the cultural diversity of the Bangla-speaking community. Despite
extensive study into translating Bangla to English, English to Bangla, and
Banglish to Bangla in the past, there has been a noticeable gap in translating
Bangla regional dialects into standard Bangla. In this study, we set out to
fill this gap by creating a collection of 32,500 sentences, encompassing
Bangla, Banglish, and English, representing five regional Bangla dialects. Our
aim is to translate these regional dialects into standard Bangla and detect
regions accurately. To achieve this, we proposed models known as mT5 and
BanglaT5 for translating regional dialects into standard Bangla. Additionally,
we employed mBERT and Bangla-bert-base to determine the specific regions from
where these dialects originated. Our experimental results showed the highest
BLEU score of 69.06 for Mymensingh regional dialects and the lowest BLEU score
of 36.75 for Chittagong regional dialects. We also observed the lowest average
word error rate of 0.1548 for Mymensingh regional dialects and the highest of
0.3385 for Chittagong regional dialects. For region detection, we achieved an
accuracy of 85.86% for Bangla-bert-base and 84.36% for mBERT. This is the first
large-scale investigation of Bangla regional dialects to Bangla machine
translation. We believe our findings will not only pave the way for future work
on Bangla regional dialects to Bangla machine translation, but will also be
useful in solving similar language-related challenges in low-resource language
conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Principled Framework for Knowledge-enhanced Large Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saizhuo Wang, Zhihan Liu, Zhaoran Wang, Jian Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are versatile, yet they often falter in tasks
requiring deep and reliable reasoning due to issues like hallucinations,
limiting their applicability in critical scenarios. This paper introduces a
rigorously designed framework for creating LLMs that effectively anchor
knowledge and employ a closed-loop reasoning process, enhancing their
capability for in-depth analysis. We dissect the framework to illustrate the
contribution of each component to the LLMs' performance, offering a theoretical
assurance of improved reasoning under well-defined assumptions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ (Why) Is My <span class="highlight-title">Prompt</span> Getting Worse? Rethinking Regression Testing for
  Evolving LLM APIs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanqin Ma, Chenyang Yang, Christian Kästner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly integrated into software
applications. Downstream application developers often access LLMs through APIs
provided as a service. However, LLM APIs are often updated silently and
scheduled to be deprecated, forcing users to continuously adapt to evolving
models. This can cause performance regression and affect prompt design choices,
as evidenced by our case study on toxicity detection. Based on our case study,
we emphasize the need for and re-examine the concept of regression testing for
evolving LLM APIs. We argue that regression testing LLMs requires fundamental
changes to traditional testing approaches, due to different correctness
notions, prompting brittleness, and non-determinism in LLM APIs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Utilizing Speech Emotion Recognition and Recommender Systems for
  Negative Emotion Handling in Therapy Chatbots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11116v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11116v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farideh Majidi, Marzieh Bahrami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emotional well-being significantly influences mental health and overall
quality of life. As therapy chatbots become increasingly prevalent, their
ability to comprehend and respond empathetically to users' emotions remains
limited. This paper addresses this limitation by proposing an approach to
enhance therapy chatbots with auditory perception, enabling them to understand
users' feelings and provide human-like empathy. The proposed method
incorporates speech emotion recognition (SER) techniques using Convolutional
Neural Network (CNN) models and the ShEMO dataset to accurately detect and
classify negative emotions, including anger, fear, and sadness. The SER model
achieves a validation accuracy of 88%, demonstrating its effectiveness in
recognizing emotional states from speech signals. Furthermore, a recommender
system is developed, leveraging the SER model's output to generate personalized
recommendations for managing negative emotions, for which a new bilingual
dataset was generated as well since there is no such dataset available for this
task. The recommender model achieves an accuracy of 98% by employing a
combination of global vectors for word representation (GloVe) and LSTM models.
To provide a more immersive and empathetic user experience, a text-to-speech
model called GlowTTS is integrated, enabling the therapy chatbot to audibly
communicate the generated recommendations to users in both English and Persian.
The proposed approach offers promising potential to enhance therapy chatbots by
providing them with the ability to recognize and respond to users' emotions,
ultimately improving the delivery of mental health support for both English and
Persian-speaking users.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the First National Conference of Artificial Intelligence
  and Software Engineering</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Responsible AI Considerations in Text Summarization Research: A <span class="highlight-title">Review</span>
  of Current Practices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11103v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11103v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Lu Liu, Meng Cao, Su Lin Blodgett, Jackie Chi Kit Cheung, Alexandra Olteanu, Adam Trischler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI and NLP publication venues have increasingly encouraged researchers to
reflect on possible ethical considerations, adverse impacts, and other
responsible AI issues their work might engender. However, for specific NLP
tasks our understanding of how prevalent such issues are, or when and why these
issues are likely to arise, remains limited. Focusing on text summarization --
a common NLP task largely overlooked by the responsible AI community -- we
examine research and reporting practices in the current literature. We conduct
a multi-round qualitative analysis of 333 summarization papers from the ACL
Anthology published between 2020-2022. We focus on how, which, and when
responsible AI issues are covered, which relevant stakeholders are considered,
and mismatches between stated and realized research goals. We also discuss
current evaluation practices and consider how authors discuss the limitations
of both prior work and their own work. Overall, we find that relatively few
papers engage with possible stakeholders or contexts of use, which limits their
consideration of potential downstream adverse impacts or other responsible AI
issues. Based on our findings, we make recommendations on concrete practices
and research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Radiology Report Generation Using <span class="highlight-title">Transformer</span>s Conditioned with
  Non-imaging Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nurbanu Aksoy, Nishant Ravikumar, Alejandro F Frangi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Medical image interpretation is central to most clinical applications such as
disease diagnosis, treatment planning, and prognostication. In clinical
practice, radiologists examine medical images and manually compile their
findings into reports, which can be a time-consuming process. Automated
approaches to radiology report generation, therefore, can reduce radiologist
workload and improve efficiency in the clinical pathway. While recent
deep-learning approaches for automated report generation from medical images
have seen some success, most studies have relied on image-derived features
alone, ignoring non-imaging patient data. Although a few studies have included
the word-level contexts along with the image, the use of patient demographics
is still unexplored. This paper proposes a novel multi-modal transformer
network that integrates chest x-ray (CXR) images and associated patient
demographic information, to synthesise patient-specific radiology reports. The
proposed network uses a convolutional neural network to extract visual features
from CXRs and a transformer-based encoder-decoder network that combines the
visual features with semantic text embeddings of patient demographic
information, to synthesise full-text radiology reports. Data from two public
databases were used to train and evaluate the proposed approach. CXRs and
reports were extracted from the MIMIC-CXR database and combined with
corresponding patients' data MIMIC-IV. Based on the evaluation metrics used
including patient demographic information was found to improve the quality of
reports generated using the proposed approach, relative to a baseline network
trained using CXRs alone. The proposed approach shows potential for enhancing
radiology report generation by leveraging rich patient metadata and combining
semantic text embeddings derived thereof, with medical image-derived visual
features.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Images: An Integrative Multi-modal Approach to Chest X-Ray Report
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11090v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11090v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nurbanu Aksoy, Serge Sharoff, Selcuk Baser, Nishant Ravikumar, Alejandro F Frangi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image-to-text radiology report generation aims to automatically produce
radiology reports that describe the findings in medical images. Most existing
methods focus solely on the image data, disregarding the other patient
information accessible to radiologists. In this paper, we present a novel
multi-modal deep neural network framework for generating chest X-rays reports
by integrating structured patient data, such as vital signs and symptoms,
alongside unstructured clinical notes.We introduce a conditioned
cross-multi-head attention module to fuse these heterogeneous data modalities,
bridging the semantic gap between visual and textual data. Experiments
demonstrate substantial improvements from using additional modalities compared
to relying on images alone. Notably, our model achieves the highest reported
performance on the ROUGE-L metric compared to relevant state-of-the-art models
in the literature. Furthermore, we employed both human evaluation and clinical
semantic similarity measurement alongside word-overlap metrics to improve the
depth of quantitative analysis. A human evaluation, conducted by a
board-certified radiologist, confirms the model's accuracy in identifying
high-level findings, however, it also highlights that more improvement is
needed to capture nuanced details and clinical context.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Combining EEG and NLP Features for Predicting Students' Lecture
  Comprehension using Ensemble Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11088v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11088v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Phantharach Natnithikarat, Theerawit Wilaiprasitporn, Supavit Kongwudhikunakorn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electroencephalography (EEG) and Natural Language Processing (NLP) can be
applied for education to measure students' comprehension in classroom lectures;
currently, the two measures have been used separately. In this work, we propose
a classification framework for predicting students' lecture comprehension in
two tasks: (i) students' confusion after listening to the simulated lecture and
(ii) the correctness of students' responses to the post-lecture assessment. The
proposed framework includes EEG and NLP feature extraction, processing, and
classification. EEG and NLP features are extracted to construct integrated
features obtained from recorded EEG signals and sentence-level syntactic
analysis, which provide information about specific biomarkers and sentence
structures. An ensemble stacking classification method -- a combination of
multiple individual models that produces an enhanced predictive model -- is
studied to learn from the features to make predictions accurately. Furthermore,
we also utilized subjective confusion ratings as another integrated feature to
enhance classification performance. By doing so, experiment results show that
this framework performs better than the baselines, which achieved F1 up to 0.65
for predicting confusion and 0.78 for predicting correctness, highlighting that
utilizing this has helped improve the classification performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adapters: A Unified Library for Parameter-Efficient and Modular Transfer
  Learning <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.11077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.11077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Clifton Poth, Hannah Sterz, Indraneil Paul, Sukannya Purkayastha, Leon Engländer, Timo Imhof, Ivan Vulić, Sebastian Ruder, Iryna Gurevych, Jonas Pfeiffer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Adapters, an open-source library that unifies
parameter-efficient and modular transfer learning in large language models. By
integrating 10 diverse adapter methods into a unified interface, Adapters
offers ease of use and flexible configuration. Our library allows researchers
and practitioners to leverage adapter modularity through composition blocks,
enabling the design of complex adapter setups. We demonstrate the library's
efficacy by evaluating its performance against full fine-tuning on various NLP
tasks. Adapters provides a powerful tool for addressing the challenges of
conventional fine-tuning paradigms and promoting more efficient and modular
transfer learning. The library is available via https://adapterhub.ml/adapters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023: Systems Demonstrations</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Pre-train</span>ing LLMs using human-like development data corpus <span class="chip">CoNLL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04666v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04666v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained Large Language Models (LLMs) have shown success in a diverse set
of language inference and understanding tasks. The pre-training stage of LLMs
looks at a large corpus of raw textual data. The BabyLM shared task compares
LLM pre-training to human language acquisition, where the number of tokens seen
by 13-year-old kids is magnitudes smaller than the number of tokens seen by
LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn
contextual word representations using roughly the same number of tokens as seen
by children. We provide a strong set of baselines; with different
architectures, evaluation of changes in performance across epochs, and reported
pre-training metrics for the strict small and strict tracks of the task. We
also try to loosely replicate the RoBERTa baseline given by the task organizers
to observe the training robustness to hyperparameter selection and
replicability. We provide the submission details to the strict and strict-small
tracks in this report.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CoNLL and CMCL 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Selection for Language Models via Importance Resampling <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.03169v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.03169v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sang Michael Xie, Shibani Santurkar, Tengyu Ma, Percy Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Selecting a suitable pretraining dataset is crucial for both general-domain
(e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We
formalize this problem as selecting a subset of a large raw unlabeled dataset
to match a desired target distribution given unlabeled target samples. Due to
the scale and dimensionality of the raw text data, existing methods use simple
heuristics or require human experts to manually curate data. Instead, we extend
the classic importance resampling approach used in low-dimensions for LM data
selection. We propose Data Selection with Importance Resampling (DSIR), an
efficient and scalable framework that estimates importance weights in a reduced
feature space for tractability and selects data with importance resampling
according to these weights. We instantiate the DSIR framework with hashed
n-gram features for efficiency, enabling the selection of 100M documents from
the full Pile dataset in 4.5 hours. To measure whether hashed n-gram features
preserve the aspects of the data that are relevant to the target, we define KL
reduction, a data metric that measures the proximity between the selected
pretraining data and the target on some feature space. Across 8 data selection
methods (including expert selection), KL reduction on hashed n-gram features
highly correlates with average downstream accuracy (r=0.82). When selecting
data for continued pretraining on a specific domain, DSIR performs comparably
to expert curation across 8 target distributions. When pretraining
general-domain models (target is Wikipedia and books), DSIR improves over
random selection and heuristic filtering baselines by 2-2.5% on the GLUE
benchmark. Code is available at https://github.com/p-lambda/dsir.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ In-context Learning and Gradient Descent Revisited 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07772v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07772v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gilad Deutch, Nadav Magar, Tomer Bar Natan, Guy Dar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) has shown impressive results in few-shot learning
tasks, yet its underlying mechanism is still not fully understood. Recent works
suggest that ICL can be thought of as a gradient descent (GD) based
optimization process. While promising, these results mainly focus on simplified
settings of ICL and provide only a preliminary evaluation of the similarities
between the two methods. In this work, we revisit the comparison between ICL
and GD-based finetuning and study what properties of ICL an equivalent process
must follow. We highlight a major difference in the flow of information between
ICL and standard finetuning. Namely, ICL can only rely on information from
lower layers at every point, while finetuning depends on loss gradients from
deeper layers. We refer to this discrepancy as Layer Causality and show that a
layer causal variant of the finetuning process aligns with ICL on par with
vanilla finetuning and is even better in most cases across relevant metrics. To
the best of our knowledge, this is the first work to discuss this discrepancy
explicitly and suggest a solution that tackles this problem with minimal
changes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Chat<span class="highlight-title">GPT</span> a game changer for geocoding -- a benchmark for geocoding
  address parsing techniques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14360v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14360v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengcong Yin, Diya Li, Daniel W. Goldberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable success of GPT models across various tasks, including toponymy
recognition motivates us to assess the performance of the GPT-3 model in the
geocoding address parsing task. To ensure that the evaluation more accurately
mirrors performance in real-world scenarios with diverse user input qualities
and resolve the pressing need for a 'gold standard' evaluation dataset for
geocoding systems, we introduce a benchmark dataset of low-quality address
descriptions synthesized based on human input patterns mining from actual input
logs of a geocoding system in production. This dataset has 21 different input
errors and variations; contains over 239,000 address records that are uniquely
selected from streets across all U.S. 50 states and D.C.; and consists of three
subsets to be used as training, validation, and testing sets. Building on this,
we train and gauge the performance of the GPT-3 model in extracting address
components, contrasting its performance with transformer-based and LSTM-based
models. The evaluation results indicate that Bidirectional LSTM-CRF model has
achieved the best performance over these transformer-based models and GPT-3
model. Transformer-based models demonstrate very comparable results compared to
the Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in
performance, showcases potential in the address parsing task with few-shot
examples, exhibiting room for improvement with additional fine-tuning. We open
source the code and data of this presented benchmark so that researchers can
utilize it for future model development or extend it to evaluate similar tasks,
such as document geocoding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Predicting Influenza A Viral Host Using PSSM and Word Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2201.01140v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2201.01140v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhua Xu, Dominik Wojtczak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid mutation of the influenza virus threatens public health.
Reassortment among viruses with different hosts can lead to a fatal pandemic.
However, it is difficult to detect the original host of the virus during or
after an outbreak as influenza viruses can circulate between different species.
Therefore, early and rapid detection of the viral host would help reduce the
further spread of the virus. We use various machine learning models with
features derived from the position-specific scoring matrix (PSSM) and features
learned from word embedding and word encoding to infer the origin host of
viruses. The results show that the performance of the PSSM-based model reaches
the MCC around 95%, and the F1 around 96%. The MCC obtained using the model
with word embedding is around 96%, and the F1 is around 97%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at CIBCB 2021. V1: accepted version + minor
  correction to table 1; V2: corrected a minor typo; V3: update the formula of
  error rate; V4: replacing 'nested cv' with 'nested k-fold cv' for better
  clarity</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generating Medical Prescriptions with Conditional <span class="highlight-title">Transformer</span> <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.19727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.19727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Warren Del-Pinto, Goran Nenadic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Access to real-world medication prescriptions is essential for medical
research and healthcare quality improvement. However, access to real medication
prescriptions is often limited due to the sensitive nature of the information
expressed. Additionally, manually labelling these instructions for training and
fine-tuning Natural Language Processing (NLP) models can be tedious and
expensive. We introduce a novel task-specific model architecture,
Label-To-Text-Transformer (\textbf{LT3}), tailored to generate synthetic
medication prescriptions based on provided labels, such as a vocabulary list of
medications and their attributes. LT3 is trained on a set of around 2K lines of
medication prescriptions extracted from the MIMIC-III database, allowing the
model to produce valuable synthetic medication prescriptions. We evaluate LT3's
performance by contrasting it with a state-of-the-art Pre-trained Language
Model (PLM), T5, analysing the quality and diversity of generated texts. We
deploy the generated synthetic data to train the SpacyNER model for the Named
Entity Recognition (NER) task over the n2c2-2018 dataset. The experiments show
that the model trained on synthetic data can achieve a 96-98\% F1 score at
Label Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and
data will be shared at
\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to: Workshop on Synthetic Data Generation with Generative AI
  (SyntheticData4ML Workshop) at NeurIPS 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Song Describer <span class="highlight-title">Dataset</span>: a Corpus of Audio Captions for
  Music-and-Language Evaluation <span class="chip">NeurIPS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10057v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10057v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilaria Manco, Benno Weck, SeungHeon Doh, Minz Won, Yixiao Zhang, Dmitry Bodganov, Yusong Wu, Ke Chen, Philip Tovstogan, Emmanouil Benetos, Elio Quinton, György Fazekas, Juhan Nam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of
high-quality audio-caption pairs, designed for the evaluation of
music-and-language models. The dataset consists of 1.1k human-written natural
language descriptions of 706 music recordings, all publicly accessible and
released under Creative Common licenses. To showcase the use of our dataset, we
benchmark popular models on three key music-and-language tasks (music
captioning, text-to-music generation and music-language retrieval). Our
experiments highlight the importance of cross-dataset evaluation and offer
insights into how researchers can use SDD to gain a broader understanding of
model performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2023 Workshop on Machine Learning for Audio</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2023-11-22T05:26:37.742742342Z">
            2023-11-22 05:26:37 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
